Beginning task setup

/usr/bin/flock
Using existing venv: /tmp/petrel-good-11-1473373415/venv
Task setup took 7 seconds
Launching: python -m petrel.run twoworddivider /root/twitterintel/twitterintel/twitterintel/topology/TopologyTweetTransformationGOOD/petrel23443_twoworddivider.log
/usr/local/lib/python2.7/dist-packages/petrel-0.9.4.0.3-py2.7.egg/petrel/run.py invoked with the following arguments: ['twoworddivider', '/root/twitterintel/twitterintel/twitterintel/topology/TopologyTweetTransformationGOOD/petrel23443_twoworddivider.log']
python version: 2.7.12
user=root
PATH=/tmp/petrel-good-11-1473373415/venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/root/zookeeper-3.4.8/bin:/root/petrel/bin:/root/apache-storm-0.9.4/bin:/root/zookeeper-3.4.8/bin:/root/petrel/bin:/root/apache-storm-0.9.4/bin
LD_LIBRARY_PATH=var/stormtmp/supervisor/stormdist/good-11-1473373415/resources/Linux-amd64:var/stormtmp/supervisor/stormdist/good-11-1473373415/resources:/usr/local/lib
PYTHON_EGG_CACHE=/tmp/petrel-good-11-1473373415/egg_cache
[2016-09-08 23:24:22,829][storm][INFO]Tuple profiling enabled. Will log tuple processing times.
[2016-09-08 23:24:24,162][storm][INFO]Task received setupInfo from Storm: {u'pidDir': u'/root/var/stormtmp/workers/676ac817-71ba-4c42-bad1-4b5104c9602e/pids', u'conf': {u'oauth.acess_token': u' 702208758362087425-HZiyl1x7Bh98cQa1WLBDYylyu10Bpl7', u'topology.tuple.serializer': u'backtype.storm.serialization.types.ListDelegateSerializer', u'topology.workers': 1, u'drpc.worker.threads': 64, u'storm.messaging.netty.client_worker_threads': 1, u'supervisor.heartbeat.frequency.secs': 5, u'topology.executor.send.buffer.size': 1024, u'drpc.childopts': u'-Xmx768m', u'nimbus.thrift.port': 6627, u'storm.zookeeper.retry.intervalceiling.millis': 30000, u'storm.local.dir': u'var/stormtmp', u'topology.receiver.buffer.size': 8, u'storm.zookeeper.servers': [u'localhost'], u'oauth.consumer_secret': u'ADf76fi3O1lKMzBxWnjqf93l3GHv28uar3bkblkvyBrAyoA23i', u'transactional.zookeeper.root': u'/transactional', u'drpc.request.timeout.secs': 600, u'topology.skip.missing.kryo.registrations': False, u'worker.heartbeat.frequency.secs': 1, u'zmq.hwm': 0, u'storm.zookeeper.connection.timeout': 15000, u'java.library.path': u'/usr/local/lib', u'topology.max.error.report.per.interval': 5, u'storm.messaging.netty.server_worker_threads': 1, u'storm.id': u'good-11-1473373415', u'supervisor.worker.start.timeout.secs': 120, u'zmq.threads': 1, u'topology.acker.executors': None, u'storm.messaging.netty.flush.check.interval.ms': 10, u'storm.messaging.netty.transfer.batch.size': 262144, u'topology.max.task.parallelism': None, u'topology.environment': None, u'storm.zookeeper.port': 2181, u'nimbus.childopts': u'-Xmx128m', u'topology.classpath': None, u'worker.childopts': u'-Xmx768m', u'drpc.queue.size': 128, u'topology.multilang.serializer': u'backtype.storm.multilang.JsonSerializer', u'storm.zookeeper.retry.times': 5, u'nimbus.monitor.freq.secs': 10, u'storm.cluster.mode': u'distributed', u'dev.zookeeper.path': u'/tmp/dev-storm-zookeeper', u'drpc.invocations.port': 3773, u'topology.tasks': None, u'storm.zookeeper.root': u'/storm', u'logviewer.childopts': u'-Xmx128m', u'storm.meta.serialization.delegate': u'backtype.storm.serialization.DefaultSerializationDelegate', u'transactional.zookeeper.port': None, u'topology.worker.receiver.thread.count': 1, u'topology.worker.childopts': None, u'topology.max.spout.pending': None, u'topology.kryo.register': None, u'petrel.host': u'server1.pipe.com', u'nimbus.cleanup.inbox.freq.secs': 600, u'storm.messaging.netty.min_wait_ms': 100, u'nimbus.task.timeout.secs': 30, u'nimbus.thrift.max_buffer_size': 1048576, u'topology.sleep.spout.wait.strategy.time.ms': 1, u'nimbus.reassign': True, u'storm.messaging.transport': u'backtype.storm.messaging.netty.Context', u'logviewer.appender.name': u'A1', u'nimbus.host': u'localhost', u'ui.port': 8080, u'supervisor.slots.ports': [6700, 6701, 6702, 6703], u'nimbus.file.copy.expiration.secs': 600, u'supervisor.monitor.frequency.secs': 3, u'ui.childopts': u'-Xmx768m', u'transactional.zookeeper.servers': None, u'zmq.linger.millis': 5000, u'topology.error.throttle.interval.secs': 10, u'topology.worker.shared.thread.pool.size': 4, u'topology.executor.receive.buffer.size': 1024, u'topology.spout.wait.strategy': u'backtype.storm.spout.SleepSpoutWaitStrategy', u'task.heartbeat.frequency.secs': 3, u'topology.transfer.buffer.size': 1024, u'storm.zookeeper.session.timeout': 20000, u'mb per worker.worker.childopts': u'-Xmx256m', u'storm.local.mode.zmq': False, u'topology.stats.sample.rate': 0.05, u'topology.fall.back.on.java.serialization': True, u'supervisor.childopts': u'-Xmx256m', u'topology.enable.message.timeouts': True, u'storm.messaging.netty.max_wait_ms': 1000, u'nimbus.topology.validator': u'backtype.storm.nimbus.DefaultTopologyValidator', u'nimbus.supervisor.timeout.secs': 60, u'topology.disruptor.wait.strategy': u'com.lmax.disruptor.BlockingWaitStrategy', u'storm.messaging.netty.buffer_size': 5242880, u'drpc.port': 3772, u'topology.kryo.factory': u'backtype.storm.serialization.DefaultKryoFactory', u'storm.zookeeper.retry.interval': 1000, u'storm.messaging.netty.max_retries': 300, u'topology.tick.tuple.freq.secs': None, u'supervisor.enable': True, u'nimbus.task.launch.secs': 120, u'task.refresh.poll.secs': 10, u'topology.message.timeout.secs': 30, u'oauth.acess_token_secret': u'IiNOTfgE3tEZvW2HDQhRKPMoOLU43NXJCXk8maj51SdAT', u'petrel.user': u'root', u'nimbus.inbox.jar.expiration.secs': 3600, u'topology.state.synchronization.timeout.secs': 60, u'topology.name': u'good', u'supervisor.worker.timeout.secs': 30, u'topology.trident.batch.emit.interval.millis': 500, u'topology.builtin.metrics.bucket.size.secs': 60, u'storm.thrift.transport': u'backtype.storm.security.auth.SimpleTransportPlugin', u'logviewer.port': 8000, u'oauth.consumer_key': u'eaFmBSxUveRJfmyZYeabti9Q9', u'topology.kryo.decorators': [], u'topology.debug': False}, u'context': {u'task->component': {u'11': u'__acker', u'10': u'WordDivider', u'1': u'CountThreeWords', u'3': u'CountTwoWords', u'2': u'CountThreeWords', u'5': u'CountWord', u'4': u'CountTwoWords', u'7': u'KafkaConsumer', u'6': u'CountWord', u'9': u'TwoWordDivider', u'8': u'ThreeWordDivider'}, u'taskid': 9}}
[2016-09-08 23:24:24,163][storm][INFO]Task sent pid to Storm
[2016-09-08 23:26:34,932][storm][DEBUG]BasicBolt profile: total_num_tuples=1, num_tuples=1, avg_read_time=0.574025 (77.7%), avg_process_time=0.164254 (22.2%), avg_ack_time=0.000488 (0.1%)
[2016-09-08 23:27:08,806][storm][DEBUG]BasicBolt profile: total_num_tuples=4, num_tuples=3, avg_read_time=0.013359 (69.5%), avg_process_time=0.005608 (29.2%), avg_ack_time=0.000251 (1.3%)
[2016-09-08 23:28:10,628][storm][DEBUG]BasicBolt profile: total_num_tuples=6, num_tuples=2, avg_read_time=0.403662 (99.9%), avg_process_time=0.000285 (0.1%), avg_ack_time=0.000012 (0.0%)
[2016-09-08 23:29:48,608][storm][DEBUG]BasicBolt profile: total_num_tuples=8, num_tuples=2, avg_read_time=0.481597 (99.7%), avg_process_time=0.001582 (0.3%), avg_ack_time=0.000010 (0.0%)
[2016-09-08 23:30:11,929][storm][DEBUG]BasicBolt profile: total_num_tuples=11, num_tuples=3, avg_read_time=0.106288 (99.6%), avg_process_time=0.000402 (0.4%), avg_ack_time=0.000014 (0.0%)
[2016-09-08 23:30:47,967][storm][DEBUG]BasicBolt profile: total_num_tuples=13, num_tuples=2, avg_read_time=0.015309 (97.0%), avg_process_time=0.000460 (2.9%), avg_ack_time=0.000016 (0.1%)
[2016-09-08 23:30:56,142][storm][DEBUG]BasicBolt profile: total_num_tuples=16, num_tuples=3, avg_read_time=0.342406 (87.5%), avg_process_time=0.049036 (12.5%), avg_ack_time=0.000033 (0.0%)
[2016-09-08 23:30:56,234][storm][INFO]Caught exception
[2016-09-08 23:30:56,236][storm][ERROR]Sent failure message ("E_BOLTFAILED__twoworddivider__server1_pipe_com__pid__23443__port__-1__taskindex__-1__UnicodeDecodeError") to Storm
[2016-09-08 23:31:01,243][storm][ERROR]Caught exception in BasicBolt.run
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/petrel-0.9.4.0.3-py2.7.egg/petrel/storm.py", line 383, in run
    self.process(tup)
  File "/root/var/stormtmp/supervisor/stormdist/good-11-1473373415/resources/twoworddivider.py", line 29, in process
    words = self.get_words(tup.values[0].encode('utf-8','ignore'))
  File "/root/var/stormtmp/supervisor/stormdist/good-11-1473373415/resources/twoworddivider.py", line 56, in get_words
    for w in nltk.word_tokenize(sentence):
  File "/tmp/petrel-good-11-1473373415/venv/local/lib/python2.7/site-packages/nltk/tokenize/__init__.py", line 93, in word_tokenize
    return [token for sent in sent_tokenize(text)
  File "/tmp/petrel-good-11-1473373415/venv/local/lib/python2.7/site-packages/nltk/tokenize/__init__.py", line 82, in sent_tokenize
    return tokenizer.tokenize(text)
  File "/tmp/petrel-good-11-1473373415/venv/local/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 1270, in tokenize
    return list(self.sentences_from_text(text, realign_boundaries))
  File "/tmp/petrel-good-11-1473373415/venv/local/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 1318, in sentences_from_text
    return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]
  File "/tmp/petrel-good-11-1473373415/venv/local/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 1309, in span_tokenize
    return [(sl.start, sl.stop) for sl in slices]
  File "/tmp/petrel-good-11-1473373415/venv/local/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 1348, in _realign_boundaries
    for sl1, sl2 in _pair_iter(slices):
  File "/tmp/petrel-good-11-1473373415/venv/local/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 355, in _pair_iter
    for el in it:
  File "/tmp/petrel-good-11-1473373415/venv/local/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 1324, in _slices_from_text
    if self.text_contains_sentbreak(context):
  File "/tmp/petrel-good-11-1473373415/venv/local/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 1369, in text_contains_sentbreak
    for t in self._annotate_tokens(self._tokenize_words(text)):
  File "/tmp/petrel-good-11-1473373415/venv/local/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 1504, in _annotate_second_pass
    for t1, t2 in _pair_iter(tokens):
  File "/tmp/petrel-good-11-1473373415/venv/local/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 354, in _pair_iter
    prev = next(it)
  File "/tmp/petrel-good-11-1473373415/venv/local/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 621, in _annotate_first_pass
    for aug_tok in tokens:
  File "/tmp/petrel-good-11-1473373415/venv/local/lib/python2.7/site-packages/nltk/tokenize/punkt.py", line 586, in _tokenize_words
    for line in plaintext.split('\n'):
UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 15: ordinal not in range(128)
[2016-09-08 23:31:01,259][storm][ERROR]The error occurred while processing this tuple: [u"RT @cristinalaila1: Delusional CUCK thinks Trump will kill us\U0001f602 but the Muslims flooding in won't? Hillary wants to increase Muslims! https:\u2026", u'1']
Worker twoworddivider exiting normally.
