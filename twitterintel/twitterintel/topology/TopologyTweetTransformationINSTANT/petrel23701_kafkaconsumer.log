Beginning task setup

/usr/bin/flock
Using existing venv: /tmp/petrel-test-4-1462969332/venv
Task setup took 1 seconds
Launching: python -m petrel.run kafkaconsumer /home/pipe/twitterintel/twitterintel/topology/TopologyTweetTransformationSPAM/petrel23701_kafkaconsumer.log
/usr/local/lib/python2.7/dist-packages/petrel-0.9.4.0.3-py2.7.egg/petrel/run.py invoked with the following arguments: ['kafkaconsumer', '/home/pipe/twitterintel/twitterintel/topology/TopologyTweetTransformationSPAM/petrel23701_kafkaconsumer.log']
python version: 2.7.11
user=root
PATH=/tmp/petrel-test-4-1462969332/venv/bin:/root/SimpleScalar/simplesim-3.0:/root/SimpleScalar/bin:/root/SimpleScalar/gcc-2.6.3:/root/SimpleScalar/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/pipe/Downloads/zookeeper-3.4.8/bin:/home/pipe/Downloads/apache-storm-0.9.4/bin
LD_LIBRARY_PATH=storm-local/supervisor/stormdist/test-4-1462969332/resources/Linux-amd64:storm-local/supervisor/stormdist/test-4-1462969332/resources:/usr/local/lib:/opt/local/lib:/usr/lib
PYTHON_EGG_CACHE=/tmp/petrel-test-4-1462969332/egg_cache
[2016-05-11 14:39:54,346][storm][INFO]Tuple profiling enabled. Will log tuple processing times.
[2016-05-11 14:39:54,412][storm][INFO]Task received setupInfo from Storm: {u'pidDir': u'/home/pipe/storm-local/workers/02b12035-f837-473c-b74d-2d1fe914c0d5/pids', u'conf': {u'oauth.acess_token': u' 702208758362087425-HZiyl1x7Bh98cQa1WLBDYylyu10Bpl7', u'topology.tuple.serializer': u'backtype.storm.serialization.types.ListDelegateSerializer', u'topology.workers': 1, u'drpc.worker.threads': 64, u'storm.messaging.netty.client_worker_threads': 1, u'supervisor.heartbeat.frequency.secs': 5, u'topology.executor.send.buffer.size': 1024, u'drpc.childopts': u'-Xmx768m', u'nimbus.thrift.port': 6627, u'storm.zookeeper.retry.intervalceiling.millis': 30000, u'storm.local.dir': u'storm-local', u'topology.receiver.buffer.size': 8, u'storm.zookeeper.servers': [u'localhost'], u'oauth.consumer_secret': u'ADf76fi3O1lKMzBxWnjqf93l3GHv28uar3bkblkvyBrAyoA23i', u'transactional.zookeeper.root': u'/transactional', u'drpc.request.timeout.secs': 600, u'topology.skip.missing.kryo.registrations': False, u'worker.heartbeat.frequency.secs': 1, u'zmq.hwm': 0, u'storm.zookeeper.connection.timeout': 15000, u'java.library.path': u'/usr/local/lib:/opt/local/lib:/usr/lib', u'topology.max.error.report.per.interval': 5, u'storm.messaging.netty.server_worker_threads': 1, u'storm.id': u'test-4-1462969332', u'supervisor.worker.start.timeout.secs': 120, u'zmq.threads': 1, u'topology.acker.executors': None, u'storm.messaging.netty.flush.check.interval.ms': 10, u'storm.messaging.netty.transfer.batch.size': 262144, u'topology.max.task.parallelism': None, u'topology.environment': None, u'storm.zookeeper.port': 2181, u'nimbus.childopts': u'-Xmx1024m', u'topology.classpath': None, u'worker.childopts': u'-Xmx768m', u'drpc.queue.size': 128, u'topology.multilang.serializer': u'backtype.storm.multilang.JsonSerializer', u'storm.zookeeper.retry.times': 5, u'nimbus.monitor.freq.secs': 10, u'storm.cluster.mode': u'distributed', u'dev.zookeeper.path': u'/tmp/dev-storm-zookeeper', u'drpc.invocations.port': 3773, u'topology.tasks': None, u'storm.zookeeper.root': u'/storm', u'logviewer.childopts': u'-Xmx128m', u'storm.meta.serialization.delegate': u'backtype.storm.serialization.DefaultSerializationDelegate', u'transactional.zookeeper.port': None, u'topology.worker.receiver.thread.count': 1, u'topology.worker.childopts': None, u'topology.max.spout.pending': None, u'topology.kryo.register': None, u'petrel.host': u'pipe-X550CC', u'nimbus.cleanup.inbox.freq.secs': 600, u'storm.messaging.netty.min_wait_ms': 100, u'nimbus.task.timeout.secs': 30, u'nimbus.thrift.max_buffer_size': 1048576, u'topology.sleep.spout.wait.strategy.time.ms': 1, u'nimbus.reassign': True, u'storm.messaging.transport': u'backtype.storm.messaging.netty.Context', u'logviewer.appender.name': u'A1', u'nimbus.host': u'localhost', u'ui.port': 8080, u'supervisor.slots.ports': [6700, 6701, 6702, 6703], u'nimbus.file.copy.expiration.secs': 600, u'supervisor.monitor.frequency.secs': 3, u'ui.childopts': u'-Xmx768m', u'transactional.zookeeper.servers': None, u'zmq.linger.millis': 5000, u'topology.error.throttle.interval.secs': 10, u'topology.worker.shared.thread.pool.size': 4, u'topology.executor.receive.buffer.size': 1024, u'topology.spout.wait.strategy': u'backtype.storm.spout.SleepSpoutWaitStrategy', u'task.heartbeat.frequency.secs': 3, u'topology.transfer.buffer.size': 1024, u'storm.zookeeper.session.timeout': 20000, u'storm.local.mode.zmq': False, u'topology.stats.sample.rate': 0.05, u'topology.fall.back.on.java.serialization': True, u'supervisor.childopts': u'-Xmx256m', u'topology.enable.message.timeouts': True, u'storm.messaging.netty.max_wait_ms': 1000, u'nimbus.topology.validator': u'backtype.storm.nimbus.DefaultTopologyValidator', u'nimbus.supervisor.timeout.secs': 60, u'topology.disruptor.wait.strategy': u'com.lmax.disruptor.BlockingWaitStrategy', u'storm.messaging.netty.buffer_size': 5242880, u'drpc.port': 3772, u'topology.kryo.factory': u'backtype.storm.serialization.DefaultKryoFactory', u'storm.zookeeper.retry.interval': 1000, u'storm.messaging.netty.max_retries': 300, u'topology.tick.tuple.freq.secs': 30, u'supervisor.enable': True, u'nimbus.task.launch.secs': 120, u'task.refresh.poll.secs': 10, u'topology.message.timeout.secs': 30, u'oauth.acess_token_secret': u'IiNOTfgE3tEZvW2HDQhRKPMoOLU43NXJCXk8maj51SdAT', u'petrel.user': u'root', u'nimbus.inbox.jar.expiration.secs': 3600, u'topology.state.synchronization.timeout.secs': 60, u'topology.name': u'test', u'supervisor.worker.timeout.secs': 30, u'topology.trident.batch.emit.interval.millis': 500, u'topology.builtin.metrics.bucket.size.secs': 60, u'storm.thrift.transport': u'backtype.storm.security.auth.SimpleTransportPlugin', u'logviewer.port': 8000, u'oauth.consumer_key': u'eaFmBSxUveRJfmyZYeabti9Q9', u'topology.kryo.decorators': [], u'topology.debug': False}, u'context': {u'task->component': {u'1': u'CountThreeWords', u'3': u'CountWord', u'2': u'CountTwoWords', u'5': u'ThreeWordDivider', u'4': u'KafkaConsumer', u'7': u'WordDivider', u'6': u'TwoWordDivider', u'8': u'__acker'}, u'taskid': 4}}
[2016-05-11 14:39:54,413][storm][INFO]Task sent pid to Storm
[2016-05-11 14:39:54,562][kafka.client][INFO]Broker version identifed as 0.9
[2016-05-11 14:39:54,564][kafka.consumer.subscription_state][INFO]Updating subscribed topics to: ['instanttopic']
[2016-05-11 14:39:54,646][kafka.cluster][INFO]Group coordinator for kafka-python-default-group is BrokerMetadata(nodeId=0, host=u'pipe-X550CC', port=9092)
[2016-05-11 14:39:54,691][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 1) with member_id kafka-python-1.0.2-4c8b1768-5d05-4385-b0c7-b291d3e772f7
[2016-05-11 14:39:54,691][kafka.coordinator][INFO]Elected group leader -- performing partition assignments using range
[2016-05-11 14:39:54,736][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'instanttopic', partition=0)]
[2016-05-11 14:39:57,833][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:40:00,858][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:40:03,871][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:40:06,933][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:40:09,952][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:40:12,967][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:40:16,021][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:40:19,040][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:40:22,059][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:40:25,076][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:40:28,135][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:40:31,152][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:40:34,169][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:40:37,225][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:40:40,245][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:40:42,760][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:40:45,821][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:40:48,838][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:40:51,894][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:40:54,908][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:40:57,924][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:41:00,981][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:41:04,000][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:41:07,022][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:41:10,043][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:41:13,103][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:41:16,124][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:41:19,140][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:41:22,197][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:41:25,212][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:41:28,232][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:41:31,287][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:41:33,807][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:41:36,831][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:41:39,844][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:41:42,900][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:41:45,914][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:41:48,956][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:41:51,981][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:41:55,006][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:41:58,068][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:42:01,087][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:42:04,108][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:42:07,168][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:42:10,191][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:42:13,215][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:42:16,238][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:42:18,801][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:42:21,862][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:42:24,883][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:42:27,942][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:42:30,961][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:42:33,981][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:42:37,040][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:42:40,063][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:42:43,082][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:42:46,103][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:42:49,165][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:42:52,192][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:42:55,218][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:42:57,774][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:43:00,831][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:43:03,852][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:43:06,862][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:43:09,919][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:43:12,940][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:43:15,962][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:43:19,023][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:43:22,044][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:43:25,062][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:43:28,123][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:43:31,143][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:43:34,169][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:43:37,192][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:43:40,249][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:43:43,268][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:43:46,286][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:43:48,847][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:43:51,869][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:43:54,895][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:43:57,952][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:44:00,968][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:44:03,980][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:44:06,999][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:44:10,055][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:44:13,073][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:44:16,096][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:44:19,157][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:44:22,176][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:44:25,200][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:44:28,258][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:44:31,281][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:44:33,802][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:44:36,854][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:44:39,876][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:44:42,898][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:44:45,954][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:44:48,972][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:44:51,992][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:44:54,797][kafka.coordinator][WARNING]Coordinator unknown during heartbeat -- will retry
[2016-05-11 14:44:54,797][kafka.coordinator][WARNING]Heartbeat failed; retrying
[2016-05-11 14:44:54,898][kafka.coordinator][WARNING]Coordinator unknown during heartbeat -- will retry
[2016-05-11 14:44:54,898][kafka.coordinator][WARNING]Heartbeat failed; retrying
[2016-05-11 14:44:54,999][kafka.coordinator][WARNING]Coordinator unknown during heartbeat -- will retry
[2016-05-11 14:44:54,999][kafka.coordinator][WARNING]Heartbeat failed; retrying
[2016-05-11 14:44:55,101][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:44:58,155][kafka.coordinator][INFO]Heartbeat successful
[2016-05-11 14:45:00,010][storm][ERROR][Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/petrel-0.9.4.0.3-py2.7.egg/petrel/storm.py", line 88, in sendMsgToParent
    old_stdout.flush()
IOError: [Errno 32] Broken pipe
[2016-05-11 14:45:00,010][storm][ERROR]Sent failure message ("E_SPOUTFAILED__kafkaconsumer__pipe-X550CC__pid__23701__port__-1__taskindex__-1__StormIPCException") to Storm
[2016-05-11 14:45:05,016][storm][ERROR]Caught exception in Spout.run: IOError error [Errno 32] in sendMsgToParent: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/petrel-0.9.4.0.3-py2.7.egg/petrel/storm.py", line 421, in run
    self.nextTuple()
  File "/home/pipe/storm-local/supervisor/stormdist/test-4-1462969332/resources/kafkaconsumer.py", line 43, in nextTuple
    storm.emit([algo,user])
  File "/usr/local/lib/python2.7/dist-packages/petrel-0.9.4.0.3-py2.7.egg/petrel/storm.py", line 125, in emit
    result = __emit(*args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/petrel-0.9.4.0.3-py2.7.egg/petrel/storm.py", line 146, in __emit
    return emitSpout(*args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/petrel-0.9.4.0.3-py2.7.egg/petrel/storm.py", line 219, in emitSpout
    sendMsgToParent(m)
  File "/usr/local/lib/python2.7/dist-packages/petrel-0.9.4.0.3-py2.7.egg/petrel/storm.py", line 94, in sendMsgToParent
    str(e)))
StormIPCException: IOError error [Errno 32] in sendMsgToParent: [Errno 32] Broken pipe
Worker kafkaconsumer exiting normally.
