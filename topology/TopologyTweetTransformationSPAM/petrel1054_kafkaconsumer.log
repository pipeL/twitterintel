Beginning task setup

/usr/bin/flock
Using existing venv: /tmp/petrel-spam-6-1473877022/venv
Task setup took 0 seconds
Launching: python -m petrel.run kafkaconsumer /home/pipe/topology/TopologyTweetTransformationSPAM/petrel1054_kafkaconsumer.log
/usr/local/lib/python2.7/dist-packages/petrel-1.0.1.0.3-py2.7.egg/petrel/run.py invoked with the following arguments: ['kafkaconsumer', '/home/pipe/topology/TopologyTweetTransformationSPAM/petrel1054_kafkaconsumer.log']
python version: 2.7.12
user=root
PATH=/tmp/petrel-spam-6-1473877022/venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin
LD_LIBRARY_PATH=/home/apache-storm-1.0.1/data/supervisor/stormdist/spam-6-1473877022/resources/Linux-amd64:/home/apache-storm-1.0.1/data/supervisor/stormdist/spam-6-1473877022/resources:/usr/local/lib:/opt/local/lib:/usr/lib
PYTHON_EGG_CACHE=/tmp/petrel-spam-6-1473877022/egg_cache
[2016-09-15 19:45:01,412][storm][INFO]Tuple profiling enabled. Will log tuple processing times.
[2016-09-15 19:45:01,670][storm][INFO]Task received setupInfo from Storm: {'pidDir': '/home/apache-storm-1.0.1/data/workers/37f0d4ff-c64a-491f-a5c4-85290d6e9b1a/pids', 'conf': {'storm.group.mapping.service.params': None, 'topology.tuple.serializer': 'org.apache.storm.serialization.types.ListDelegateSerializer', 'topology.workers': 1, 'drpc.worker.threads': 64, 'ui.filter.params': None, 'transactional.zookeeper.root': '/transactional', 'logviewer.cleanup.age.mins': 10080, 'worker.profiler.command': 'flight.bash', 'topology.executor.send.buffer.size': 1024, 'nimbus.file.copy.expiration.secs': 600, 'oauth.acess_token': ' 702208758362087425-HZiyl1x7Bh98cQa1WLBDYylyu10Bpl7', 'drpc.childopts': '-Xmx768m', 'nimbus.thrift.port': 6627, 'topology.disruptor.wait.timeout.millis': 1000, 'storm.zookeeper.retry.intervalceiling.millis': 30000, 'storm.local.dir': '/home/apache-storm-1.0.1/data', 'storm.auth.simple-acl.users': [], 'drpc.invocations.threads': 64, 'storm.zookeeper.superACL': None, 'storm.cluster.state.store': 'org.apache.storm.cluster_state.zookeeper_state_factory', 'storm.codedistributor.class': 'org.apache.storm.codedistributor.LocalFileSystemCodeDistributor', 'drpc.https.keystore.password': '', 'supervisor.blobstore.download.max_retries': 3, 'pacemaker.kerberos.users': [], 'storm.messaging.netty.client_worker_threads': 1, 'oauth.consumer_secret': 'ADf76fi3O1lKMzBxWnjqf93l3GHv28uar3bkblkvyBrAyoA23i', 'topology.component.resources.offheap.memory.mb': 0.0, 'supervisor.heartbeat.frequency.secs': 5, 'storm.group.mapping.service.cache.duration.secs': 120, 'storm.group.mapping.service': 'org.apache.storm.security.auth.ShellBasedGroupsMapping', 'storm.workers.artifacts.dir': 'workers-artifacts', 'drpc.request.timeout.secs': 600, 'pacemaker.childopts': '-Xmx1024m', 'nimbus.seeds': ['localhost'], 'topology.shellbolt.max.pending': 100, 'topology.min.replication.count': 1, 'topology.skip.missing.kryo.registrations': False, 'worker.heartbeat.frequency.secs': 1, 'storm.auth.simple-acl.users.commands': [], 'storm.zookepeer.port': 2181, 'zmq.hwm': 0, 'topology.worker.shared.thread.pool.size': 4, 'storm.zookeeper.connection.timeout': 15000, 'java.library.path': '/usr/local/lib:/opt/local/lib:/usr/lib', 'logviewer.max.sum.worker.logs.size.mb': 4096, 'task.refresh.poll.secs': 10, 'topology.max.error.report.per.interval': 5, 'topology.worker.logwriter.childopts': '-Xmx64m', 'ui.actions.enabled': True, 'storm.health.check.timeout.ms': 5000, 'topology.scheduler.strategy': 'org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy', 'ui.host': '0.0.0.0', 'storm.messaging.netty.server_worker_threads': 1, 'topology.disruptor.batch.size': 100, 'storm.id': 'spam-6-1473877022', 'supervisor.worker.start.timeout.secs': 120, 'zmq.threads': 1, 'topology.acker.executors': None, 'pacemaker.thread.timeout': 10, 'storm.local.mode.zmq': False, 'topology.eventlogger.executors': 0, 'topology.tick.tuple.freq.secs': 30, 'supervisor.memory.capacity.mb': 3072.0, 'supervisor.worker.shutdown.sleep.secs': 1, 'pacemaker.base.threads': 10, 'drpc.http.creds.plugin': 'org.apache.storm.security.auth.DefaultHttpCredentialsPlugin', 'storm.zookeeper.servers': ['localhost'], 'supervisor.localizer.cache.target.size.mb': 10240, 'storm.messaging.netty.transfer.batch.size': 262144, 'resource.aware.scheduler.eviction.strategy': 'org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy', 'topology.environment': None, 'storm.zookeeper.port': 2181, 'storm.auth.simple-acl.admins': [], 'pacemaker.host': 'localhost', 'nimbus.childopts': '-Xmx1024m', 'storm.principal.tolocal': 'org.apache.storm.security.auth.DefaultPrincipalToLocal', 'storm.nimbus.retry.times': 5, 'topology.classpath': None, 'drpc.authorizer.acl.filename': 'drpc-auth-acl.yaml', 'topology.bolts.outgoing.overflow.buffer.enable': False, 'nimbus.credential.renewers.freq.secs': 600, 'worker.childopts': '-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump', 'drpc.queue.size': 128, 'supervisor.blobstore.class': 'org.apache.storm.blobstore.NimbusBlobStore', 'topology.multilang.serializer': 'org.apache.storm.multilang.JsonSerializer', 'storm.zookeeper.retry.times': 5, 'topology.disable.loadaware': False, 'supervisor.run.worker.as.user': False, 'storm.blobstore.replication.factor': 3, 'worker.profiler.childopts': '-XX:+UnlockCommercialFeatures -XX:+FlightRecorder', 'nimbus.thrift.threads': 64, 'nimbus.monitor.freq.secs': 10, 'storm.blobstore.inputstream.buffer.size.bytes': 65536, 'dev.zookeeper.path': '/tmp/dev-storm-zookeeper', 'topology.users': [], 'storm.daemon.metrics.reporter.plugins': ['org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter'], 'storm.exhibitor.poll.uripath': '/exhibitor/v1/cluster/list', 'pacemaker.max.threads': 50, 'drpc.https.keystore.type': 'JKS', 'topology.tasks': None, 'storm.zookeeper.root': '/storm', 'logviewer.childopts': '-Xmx128m', 'topology.max.replication.wait.time.sec': 60, 'worker.gc.childopts': '', 'backpressure.disruptor.low.watermark': 0.4, 'storm.meta.serialization.delegate': 'org.apache.storm.serialization.GzipThriftSerializationDelegate', 'transactional.zookeeper.port': None, 'drpc.max_buffer_size': 1048576, 'topology.worker.childopts': None, 'storm.auth.simple-white-list.users': [], 'topology.max.spout.pending': None, 'nimbus.topology.validator': 'org.apache.storm.nimbus.DefaultTopologyValidator', 'topology.kryo.register': None, 'petrel.host': 'localhost', 'client.blobstore.class': 'org.apache.storm.blobstore.NimbusBlobStore', 'nimbus.cleanup.inbox.freq.secs': 600, 'storm.nimbus.retry.intervalceiling.millis': 60000, 'storm.network.topography.plugin': 'org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping', 'storm.messaging.netty.min_wait_ms': 100, 'nimbus.task.timeout.secs': 30, 'topology.disruptor.batch.timeout.millis': 1, 'topology.state.checkpoint.interval.ms': 1000, 'ui.header.buffer.bytes': 4096, 'nimbus.thrift.max_buffer_size': 1048576, 'ui.http.creds.plugin': 'org.apache.storm.security.auth.DefaultHttpCredentialsPlugin', 'topology.sleep.spout.wait.strategy.time.ms': 1, 'nimbus.blobstore.expiration.secs': 600, 'storm.cluster.mode': 'distributed', 'storm.messaging.netty.socket.backlog': 500, 'worker.profiler.enabled': False, 'nimbus.queue.size': 100000, 'logviewer.appender.name': 'A1', 'drpc.authorizer.acl.strict': False, 'ui.port': 8080, 'supervisor.slots.ports': [6700, 6701, 6702, 6703], 'worker.log.level.reset.poll.secs': 30, 'storm.nimbus.retry.interval.millis': 2000, 'drpc.invocations.port': 3773, 'supervisor.monitor.frequency.secs': 3, 'ui.childopts': '-Xmx768m', 'transactional.zookeeper.servers': None, 'storm.log4j2.conf.dir': 'log4j2', 'supervisor.supervisors': [], 'zmq.linger.millis': 5000, 'topology.error.throttle.interval.secs': 10, 'storm.health.check.dir': 'healthchecks', 'topology.executor.receive.buffer.size': 1024, 'nimbus.impersonation.authorizer': 'org.apache.storm.security.auth.authorizer.ImpersonationAuthorizer', 'topology.submitter.principal': '', 'topology.worker.max.heap.size.mb': 768.0, 'topology.spout.wait.strategy': 'org.apache.storm.spout.SleepSpoutWaitStrategy', 'task.heartbeat.frequency.secs': 3, 'topology.transfer.buffer.size': 1024, 'storm.zookeeper.session.timeout': 20000, 'topology.testing.always.try.serialize': False, 'nimbus.blobstore.class': 'org.apache.storm.blobstore.LocalFsBlobStore', 'topology.stats.sample.rate': 0.05, 'topology.fall.back.on.java.serialization': True, 'storm.exhibitor.port': 8080, 'storm.zookeeper.auth.password': None, 'supervisor.childopts': '-Xmx256m', 'topology.backpressure.enable': True, 'pacemaker.port': 6699, 'topology.enable.message.timeouts': True, 'nimbus.code.sync.freq.secs': 120, 'backpressure.disruptor.high.watermark': 0.9, 'storm.messaging.netty.max_wait_ms': 1000, 'topology.worker.receiver.thread.count': 1, 'topology.component.resources.onheap.memory.mb': 128.0, 'resource.aware.scheduler.priority.strategy': 'org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy', 'nimbus.supervisor.timeout.secs': 60, 'pacemaker.auth.method': 'NONE', 'drpc.https.port': -1, 'nimbus.inbox.jar.expiration.secs': 3600, 'scheduler.display.resource': False, 'topology.kryo.factory': 'org.apache.storm.serialization.DefaultKryoFactory', 'storm.zookeeper.retry.interval': 1000, 'supervisor.supervisors.commands': [], 'supervisor.localizer.cleanup.interval.ms': 600000, 'storm.messaging.netty.max_retries': 300, 'task.credentials.poll.secs': 30, 'drpc.http.port': 3774, 'storm.messaging.transport': 'org.apache.storm.messaging.netty.Context', 'supervisor.enable': True, 'nimbus.task.launch.secs': 120, 'supervisor.blobstore.download.thread.count': 5, 'topology.message.timeout.secs': 30, 'oauth.acess_token_secret': 'IiNOTfgE3tEZvW2HDQhRKPMoOLU43NXJCXk8maj51SdAT', 'storm.messaging.netty.authentication': False, 'petrel.user': 'pipe', 'drpc.port': 3772, 'storm.messaging.netty.buffer_size': 5242880, 'topology.state.synchronization.timeout.secs': 60, 'worker.heap.memory.mb': 768, 'topology.name': 'spam', 'topology.priority': 29, 'supervisor.worker.timeout.secs': 30, 'ui.filter': None, 'topology.trident.batch.emit.interval.millis': 500, 'topology.max.task.parallelism': None, 'supervisor.cpu.capacity': 400.0, 'topology.submitter.user': 'root', 'logviewer.max.per.worker.logs.size.mb': 2048, 'nimbus.host': 'localhost', 'topology.builtin.metrics.bucket.size.secs': 60, 'topology.component.cpu.pcore.percent': 10.0, 'ui.users': None, 'storm.thrift.transport': 'org.apache.storm.security.auth.SimpleTransportPlugin', 'logs.users': None, 'logviewer.port': 8000, 'oauth.consumer_key': 'eaFmBSxUveRJfmyZYeabti9Q9', 'topology.kryo.decorators': [], 'topology.debug': False, 'storm.zookeeper.auth.user': None}, 'context': {'task->component': {'11': '__acker', '10': 'WordDivider', '1': 'CountThreeWords', '3': 'CountTwoWords', '2': 'CountThreeWords', '5': 'CountWord', '4': 'CountTwoWords', '7': 'KafkaConsumer', '6': 'CountWord', '9': 'TwoWordDivider', '8': 'ThreeWordDivider'}, 'stream->target->grouping': {'default': {'WordDivider': {'type': 'SHUFFLE'}, 'ThreeWordDivider': {'type': 'SHUFFLE'}, 'TwoWordDivider': {'type': 'SHUFFLE'}}}, 'source->stream->fields': {}, 'streams': ['default'], 'stream->outputfields': {'default': ['sentence', 'user']}, 'taskid': 7, 'source->stream->grouping': {}, 'componentid': 'KafkaConsumer'}}
[2016-09-15 19:45:01,680][storm][INFO]Task sent pid to Storm
[2016-09-15 19:45:01,792][kafka.conn][INFO]Broker version identifed as 0.10
[2016-09-15 19:45:01,793][kafka.conn][INFO]Set configuration api_version=(0, 10) to skip auto check_version requests on startup
[2016-09-15 19:45:01,798][kafka.consumer.subscription_state][INFO]Updating subscribed topics to: ['spamtopic']
[2016-09-15 19:45:01,799][kafka.cluster][INFO]Group coordinator for kafka-python-default-group is BrokerMetadata(nodeId=0, host=u'localhost', port=9092, rack=None)
[2016-09-15 19:45:01,799][kafka.coordinator][INFO]Discovered coordinator 0 for group kafka-python-default-group
[2016-09-15 19:45:01,799][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([]) for group kafka-python-default-group
[2016-09-15 19:45:01,800][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:45:24,640][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4938) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:45:24,640][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 4938
[2016-09-15 19:45:24,641][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-15 19:45:24,641][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:45:27,649][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-15 19:45:27,649][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-15 19:45:27,751][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-15 19:45:28,151][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:45:28,151][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:45:28,155][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4939) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:45:28,155][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:45:31,666][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4940) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:45:31,667][kafka.coordinator.consumer][WARNING]Auto offset commit failed for group kafka-python-default-group: CommitFailedError: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured session.timeout.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
[2016-09-15 19:45:31,668][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 4940
[2016-09-15 19:45:31,669][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-15 19:45:31,669][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:45:34,678][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-15 19:45:34,679][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-15 19:45:34,780][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-15 19:45:35,180][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:45:35,181][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:45:35,183][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4941) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:45:35,184][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 4941
[2016-09-15 19:45:35,184][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-15 19:45:35,186][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:45:38,194][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-15 19:45:38,194][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-15 19:45:38,295][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-15 19:45:38,696][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:45:38,696][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:45:38,698][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4942) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:45:38,699][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 4942
[2016-09-15 19:45:38,699][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-15 19:45:38,700][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:45:41,707][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-15 19:45:41,707][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-15 19:45:41,808][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-15 19:45:42,208][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:45:42,208][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:45:42,213][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4943) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:45:42,215][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 4943
[2016-09-15 19:45:42,216][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-15 19:45:42,216][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:45:45,222][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-15 19:45:45,223][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-15 19:45:45,324][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-15 19:45:45,724][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:45:45,724][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:45:45,725][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4944) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:45:45,727][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 4944
[2016-09-15 19:45:45,727][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-15 19:45:45,727][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:45:48,736][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-15 19:45:48,737][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-15 19:45:48,838][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-15 19:45:49,238][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:45:49,238][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:45:49,240][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4945) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:45:49,242][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 4945
[2016-09-15 19:45:49,243][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-15 19:45:49,243][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:45:52,251][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-15 19:45:52,252][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-15 19:45:52,353][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-15 19:45:52,796][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:45:52,796][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:45:52,833][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4946) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:45:52,835][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 4946
[2016-09-15 19:45:52,836][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-15 19:45:52,836][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:45:55,852][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-15 19:45:55,853][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-15 19:45:55,954][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-15 19:45:56,354][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:45:56,354][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:45:56,355][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4947) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:45:56,361][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 4947
[2016-09-15 19:45:56,361][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-15 19:45:56,361][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:45:59,368][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-15 19:45:59,369][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-15 19:45:59,470][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-15 19:45:59,870][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:45:59,870][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:45:59,873][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4948) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:45:59,876][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 4948
[2016-09-15 19:45:59,879][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-15 19:45:59,879][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:46:02,888][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-15 19:46:02,888][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-15 19:46:02,989][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-15 19:46:03,391][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:46:03,391][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:46:03,392][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4949) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:46:03,394][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 4949
[2016-09-15 19:46:03,394][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-15 19:46:03,394][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:46:06,402][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-15 19:46:06,402][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-15 19:46:06,503][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-15 19:46:06,905][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:46:06,905][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:46:06,907][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4950) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:46:06,911][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 4950
[2016-09-15 19:46:06,911][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-15 19:46:06,911][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:46:09,924][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-15 19:46:09,924][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-15 19:46:10,025][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-15 19:46:10,426][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:46:10,426][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:46:10,427][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4951) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:46:10,435][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 4951
[2016-09-15 19:46:10,436][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-15 19:46:10,436][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:46:13,443][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-15 19:46:13,444][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-15 19:46:13,545][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-15 19:46:13,945][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:46:13,945][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:46:13,946][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4952) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:46:13,948][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 4952
[2016-09-15 19:46:13,948][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-15 19:46:13,949][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:46:16,957][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-15 19:46:16,957][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-15 19:46:17,059][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-15 19:46:17,460][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:46:17,460][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:46:17,461][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4953) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:46:17,464][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 4953
[2016-09-15 19:46:17,464][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-15 19:46:17,466][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:46:20,476][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-15 19:46:20,476][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-15 19:46:20,577][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-15 19:46:20,977][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:46:20,977][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:46:20,980][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4954) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:46:20,982][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 4954
[2016-09-15 19:46:20,982][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-15 19:46:20,982][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:46:23,992][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-15 19:46:23,992][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-15 19:46:24,094][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-15 19:46:24,494][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:46:24,494][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:46:24,499][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4955) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:46:24,499][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:46:28,013][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4956) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:46:28,014][kafka.coordinator.consumer][WARNING]Auto offset commit failed for group kafka-python-default-group: CommitFailedError: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured session.timeout.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
[2016-09-15 19:46:28,014][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 4956
[2016-09-15 19:46:28,015][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-15 19:46:28,015][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:46:31,022][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-15 19:46:31,022][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-15 19:46:31,123][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-15 19:46:31,524][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:46:31,524][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:46:31,528][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4957) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:46:31,529][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 4957
[2016-09-15 19:46:31,530][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-15 19:46:31,530][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:46:34,539][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-15 19:46:34,539][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-15 19:46:34,640][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-15 19:46:35,041][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-15 19:46:35,041][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-15 19:46:35,043][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 4958) with member_id kafka-python-1.3.1-fb658d18-a2d9-45ea-ac7e-15d0f0e6bfa2
[2016-09-15 19:46:35,044][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 4958
[2016-09-15 19:46:35,044][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-15 19:46:35,045][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
