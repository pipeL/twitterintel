Beginning task setup

/usr/bin/flock
Using existing venv: /tmp/petrel-spam-6-1473877022/venv
Task setup took 0 seconds
Launching: python -m petrel.run kafkaconsumer /home/pipe/topology/TopologyTweetTransformationSPAM/petrel20699_kafkaconsumer.log
/usr/local/lib/python2.7/dist-packages/petrel-1.0.1.0.3-py2.7.egg/petrel/run.py invoked with the following arguments: ['kafkaconsumer', '/home/pipe/topology/TopologyTweetTransformationSPAM/petrel20699_kafkaconsumer.log']
python version: 2.7.12
user=root
PATH=/tmp/petrel-spam-6-1473877022/venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin
LD_LIBRARY_PATH=/home/apache-storm-1.0.1/data/supervisor/stormdist/spam-6-1473877022/resources/Linux-amd64:/home/apache-storm-1.0.1/data/supervisor/stormdist/spam-6-1473877022/resources:/usr/local/lib:/opt/local/lib:/usr/lib
PYTHON_EGG_CACHE=/tmp/petrel-spam-6-1473877022/egg_cache
[2016-09-14 20:46:22,019][storm][INFO]Tuple profiling enabled. Will log tuple processing times.
[2016-09-14 20:46:22,377][storm][INFO]Task received setupInfo from Storm: {'pidDir': '/home/apache-storm-1.0.1/data/workers/9cd6617c-0750-4720-8797-ca4a6c61dc0b/pids', 'conf': {'storm.group.mapping.service.params': None, 'topology.tuple.serializer': 'org.apache.storm.serialization.types.ListDelegateSerializer', 'topology.workers': 1, 'drpc.worker.threads': 64, 'ui.filter.params': None, 'transactional.zookeeper.root': '/transactional', 'logviewer.cleanup.age.mins': 10080, 'worker.profiler.command': 'flight.bash', 'topology.executor.send.buffer.size': 1024, 'nimbus.file.copy.expiration.secs': 600, 'oauth.acess_token': ' 702208758362087425-HZiyl1x7Bh98cQa1WLBDYylyu10Bpl7', 'drpc.childopts': '-Xmx768m', 'nimbus.thrift.port': 6627, 'topology.disruptor.wait.timeout.millis': 1000, 'storm.zookeeper.retry.intervalceiling.millis': 30000, 'storm.local.dir': '/home/apache-storm-1.0.1/data', 'storm.auth.simple-acl.users': [], 'drpc.invocations.threads': 64, 'storm.zookeeper.superACL': None, 'storm.cluster.state.store': 'org.apache.storm.cluster_state.zookeeper_state_factory', 'storm.codedistributor.class': 'org.apache.storm.codedistributor.LocalFileSystemCodeDistributor', 'drpc.https.keystore.password': '', 'supervisor.blobstore.download.max_retries': 3, 'pacemaker.kerberos.users': [], 'storm.messaging.netty.client_worker_threads': 1, 'oauth.consumer_secret': 'ADf76fi3O1lKMzBxWnjqf93l3GHv28uar3bkblkvyBrAyoA23i', 'topology.component.resources.offheap.memory.mb': 0.0, 'supervisor.heartbeat.frequency.secs': 5, 'storm.group.mapping.service.cache.duration.secs': 120, 'storm.group.mapping.service': 'org.apache.storm.security.auth.ShellBasedGroupsMapping', 'storm.workers.artifacts.dir': 'workers-artifacts', 'drpc.request.timeout.secs': 600, 'pacemaker.childopts': '-Xmx1024m', 'nimbus.seeds': ['localhost'], 'topology.shellbolt.max.pending': 100, 'topology.min.replication.count': 1, 'topology.skip.missing.kryo.registrations': False, 'worker.heartbeat.frequency.secs': 1, 'storm.auth.simple-acl.users.commands': [], 'storm.zookepeer.port': 2181, 'zmq.hwm': 0, 'topology.worker.shared.thread.pool.size': 4, 'storm.zookeeper.connection.timeout': 15000, 'java.library.path': '/usr/local/lib:/opt/local/lib:/usr/lib', 'logviewer.max.sum.worker.logs.size.mb': 4096, 'task.refresh.poll.secs': 10, 'topology.max.error.report.per.interval': 5, 'topology.worker.logwriter.childopts': '-Xmx64m', 'ui.actions.enabled': True, 'storm.health.check.timeout.ms': 5000, 'topology.scheduler.strategy': 'org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy', 'ui.host': '0.0.0.0', 'storm.messaging.netty.server_worker_threads': 1, 'topology.disruptor.batch.size': 100, 'storm.id': 'spam-6-1473877022', 'supervisor.worker.start.timeout.secs': 120, 'zmq.threads': 1, 'topology.acker.executors': None, 'pacemaker.thread.timeout': 10, 'storm.local.mode.zmq': False, 'topology.eventlogger.executors': 0, 'topology.tick.tuple.freq.secs': 30, 'supervisor.memory.capacity.mb': 3072.0, 'supervisor.worker.shutdown.sleep.secs': 1, 'pacemaker.base.threads': 10, 'drpc.http.creds.plugin': 'org.apache.storm.security.auth.DefaultHttpCredentialsPlugin', 'storm.zookeeper.servers': ['localhost'], 'supervisor.localizer.cache.target.size.mb': 10240, 'storm.messaging.netty.transfer.batch.size': 262144, 'resource.aware.scheduler.eviction.strategy': 'org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy', 'topology.environment': None, 'storm.zookeeper.port': 2181, 'storm.auth.simple-acl.admins': [], 'pacemaker.host': 'localhost', 'nimbus.childopts': '-Xmx1024m', 'storm.principal.tolocal': 'org.apache.storm.security.auth.DefaultPrincipalToLocal', 'storm.nimbus.retry.times': 5, 'topology.classpath': None, 'drpc.authorizer.acl.filename': 'drpc-auth-acl.yaml', 'topology.bolts.outgoing.overflow.buffer.enable': False, 'nimbus.credential.renewers.freq.secs': 600, 'worker.childopts': '-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump', 'drpc.queue.size': 128, 'supervisor.blobstore.class': 'org.apache.storm.blobstore.NimbusBlobStore', 'topology.multilang.serializer': 'org.apache.storm.multilang.JsonSerializer', 'storm.zookeeper.retry.times': 5, 'topology.disable.loadaware': False, 'supervisor.run.worker.as.user': False, 'storm.blobstore.replication.factor': 3, 'worker.profiler.childopts': '-XX:+UnlockCommercialFeatures -XX:+FlightRecorder', 'nimbus.thrift.threads': 64, 'nimbus.monitor.freq.secs': 10, 'storm.blobstore.inputstream.buffer.size.bytes': 65536, 'dev.zookeeper.path': '/tmp/dev-storm-zookeeper', 'topology.users': [], 'storm.daemon.metrics.reporter.plugins': ['org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter'], 'storm.exhibitor.poll.uripath': '/exhibitor/v1/cluster/list', 'pacemaker.max.threads': 50, 'drpc.https.keystore.type': 'JKS', 'topology.tasks': None, 'storm.zookeeper.root': '/storm', 'logviewer.childopts': '-Xmx128m', 'topology.max.replication.wait.time.sec': 60, 'worker.gc.childopts': '', 'backpressure.disruptor.low.watermark': 0.4, 'storm.meta.serialization.delegate': 'org.apache.storm.serialization.GzipThriftSerializationDelegate', 'transactional.zookeeper.port': None, 'drpc.max_buffer_size': 1048576, 'topology.worker.childopts': None, 'storm.auth.simple-white-list.users': [], 'topology.max.spout.pending': None, 'nimbus.topology.validator': 'org.apache.storm.nimbus.DefaultTopologyValidator', 'topology.kryo.register': None, 'petrel.host': 'localhost', 'client.blobstore.class': 'org.apache.storm.blobstore.NimbusBlobStore', 'nimbus.cleanup.inbox.freq.secs': 600, 'storm.nimbus.retry.intervalceiling.millis': 60000, 'storm.network.topography.plugin': 'org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping', 'storm.messaging.netty.min_wait_ms': 100, 'nimbus.task.timeout.secs': 30, 'topology.disruptor.batch.timeout.millis': 1, 'topology.state.checkpoint.interval.ms': 1000, 'ui.header.buffer.bytes': 4096, 'nimbus.thrift.max_buffer_size': 1048576, 'ui.http.creds.plugin': 'org.apache.storm.security.auth.DefaultHttpCredentialsPlugin', 'topology.sleep.spout.wait.strategy.time.ms': 1, 'nimbus.blobstore.expiration.secs': 600, 'storm.cluster.mode': 'distributed', 'storm.messaging.netty.socket.backlog': 500, 'worker.profiler.enabled': False, 'nimbus.queue.size': 100000, 'logviewer.appender.name': 'A1', 'drpc.authorizer.acl.strict': False, 'ui.port': 8080, 'supervisor.slots.ports': [6700, 6701, 6702, 6703], 'worker.log.level.reset.poll.secs': 30, 'storm.nimbus.retry.interval.millis': 2000, 'drpc.invocations.port': 3773, 'supervisor.monitor.frequency.secs': 3, 'ui.childopts': '-Xmx768m', 'transactional.zookeeper.servers': None, 'storm.log4j2.conf.dir': 'log4j2', 'supervisor.supervisors': [], 'zmq.linger.millis': 5000, 'topology.error.throttle.interval.secs': 10, 'storm.health.check.dir': 'healthchecks', 'topology.executor.receive.buffer.size': 1024, 'nimbus.impersonation.authorizer': 'org.apache.storm.security.auth.authorizer.ImpersonationAuthorizer', 'topology.submitter.principal': '', 'topology.worker.max.heap.size.mb': 768.0, 'topology.spout.wait.strategy': 'org.apache.storm.spout.SleepSpoutWaitStrategy', 'task.heartbeat.frequency.secs': 3, 'topology.transfer.buffer.size': 1024, 'storm.zookeeper.session.timeout': 20000, 'topology.testing.always.try.serialize': False, 'nimbus.blobstore.class': 'org.apache.storm.blobstore.LocalFsBlobStore', 'topology.stats.sample.rate': 0.05, 'topology.fall.back.on.java.serialization': True, 'storm.exhibitor.port': 8080, 'storm.zookeeper.auth.password': None, 'supervisor.childopts': '-Xmx256m', 'topology.backpressure.enable': True, 'pacemaker.port': 6699, 'topology.enable.message.timeouts': True, 'nimbus.code.sync.freq.secs': 120, 'backpressure.disruptor.high.watermark': 0.9, 'storm.messaging.netty.max_wait_ms': 1000, 'topology.worker.receiver.thread.count': 1, 'topology.component.resources.onheap.memory.mb': 128.0, 'resource.aware.scheduler.priority.strategy': 'org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy', 'nimbus.supervisor.timeout.secs': 60, 'pacemaker.auth.method': 'NONE', 'drpc.https.port': -1, 'nimbus.inbox.jar.expiration.secs': 3600, 'scheduler.display.resource': False, 'topology.kryo.factory': 'org.apache.storm.serialization.DefaultKryoFactory', 'storm.zookeeper.retry.interval': 1000, 'supervisor.supervisors.commands': [], 'supervisor.localizer.cleanup.interval.ms': 600000, 'storm.messaging.netty.max_retries': 300, 'task.credentials.poll.secs': 30, 'drpc.http.port': 3774, 'storm.messaging.transport': 'org.apache.storm.messaging.netty.Context', 'supervisor.enable': True, 'nimbus.task.launch.secs': 120, 'supervisor.blobstore.download.thread.count': 5, 'topology.message.timeout.secs': 30, 'oauth.acess_token_secret': 'IiNOTfgE3tEZvW2HDQhRKPMoOLU43NXJCXk8maj51SdAT', 'storm.messaging.netty.authentication': False, 'petrel.user': 'pipe', 'drpc.port': 3772, 'storm.messaging.netty.buffer_size': 5242880, 'topology.state.synchronization.timeout.secs': 60, 'worker.heap.memory.mb': 768, 'topology.name': 'spam', 'topology.priority': 29, 'supervisor.worker.timeout.secs': 30, 'ui.filter': None, 'topology.trident.batch.emit.interval.millis': 500, 'topology.max.task.parallelism': None, 'supervisor.cpu.capacity': 400.0, 'topology.submitter.user': 'root', 'logviewer.max.per.worker.logs.size.mb': 2048, 'nimbus.host': 'localhost', 'topology.builtin.metrics.bucket.size.secs': 60, 'topology.component.cpu.pcore.percent': 10.0, 'ui.users': None, 'storm.thrift.transport': 'org.apache.storm.security.auth.SimpleTransportPlugin', 'logs.users': None, 'logviewer.port': 8000, 'oauth.consumer_key': 'eaFmBSxUveRJfmyZYeabti9Q9', 'topology.kryo.decorators': [], 'topology.debug': False, 'storm.zookeeper.auth.user': None}, 'context': {'task->component': {'11': '__acker', '10': 'WordDivider', '1': 'CountThreeWords', '3': 'CountTwoWords', '2': 'CountThreeWords', '5': 'CountWord', '4': 'CountTwoWords', '7': 'KafkaConsumer', '6': 'CountWord', '9': 'TwoWordDivider', '8': 'ThreeWordDivider'}, 'stream->target->grouping': {'default': {'WordDivider': {'type': 'SHUFFLE'}, 'ThreeWordDivider': {'type': 'SHUFFLE'}, 'TwoWordDivider': {'type': 'SHUFFLE'}}}, 'source->stream->fields': {}, 'streams': ['default'], 'stream->outputfields': {'default': ['sentence', 'user']}, 'taskid': 7, 'source->stream->grouping': {}, 'componentid': 'KafkaConsumer'}}
[2016-09-14 20:46:22,392][storm][INFO]Task sent pid to Storm
[2016-09-14 20:46:22,520][kafka.conn][INFO]Broker version identifed as 0.10
[2016-09-14 20:46:22,520][kafka.conn][INFO]Set configuration api_version=(0, 10) to skip auto check_version requests on startup
[2016-09-14 20:46:22,524][kafka.consumer.subscription_state][INFO]Updating subscribed topics to: ['spamtopic']
[2016-09-14 20:46:22,525][kafka.cluster][INFO]Group coordinator for kafka-python-default-group is BrokerMetadata(nodeId=0, host=u'localhost', port=9092, rack=None)
[2016-09-14 20:46:22,526][kafka.coordinator][INFO]Discovered coordinator 0 for group kafka-python-default-group
[2016-09-14 20:46:22,526][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([]) for group kafka-python-default-group
[2016-09-14 20:46:22,526][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 20:46:43,077][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 2626) with member_id kafka-python-1.3.1-13e231a2-cab1-4ece-9aaa-7f8f30cc4b6a
[2016-09-14 20:46:43,080][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 2626
[2016-09-14 20:46:43,080][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 20:46:43,081][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:46:46,087][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 20:46:46,087][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 20:46:46,188][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 20:46:46,589][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:46:46,589][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 20:46:46,596][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 2627) with member_id kafka-python-1.3.1-13e231a2-cab1-4ece-9aaa-7f8f30cc4b6a
[2016-09-14 20:46:46,597][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 2627
[2016-09-14 20:46:46,598][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 20:46:46,598][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:46:49,610][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 20:46:49,610][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 20:46:49,711][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 20:46:50,114][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:46:50,114][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 20:46:50,114][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 2628) with member_id kafka-python-1.3.1-13e231a2-cab1-4ece-9aaa-7f8f30cc4b6a
[2016-09-14 20:46:50,117][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 2628
[2016-09-14 20:46:50,117][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 20:46:50,117][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:46:53,124][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 20:46:53,124][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 20:46:53,224][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 20:46:53,626][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:46:53,626][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 20:46:53,627][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 2629) with member_id kafka-python-1.3.1-13e231a2-cab1-4ece-9aaa-7f8f30cc4b6a
[2016-09-14 20:46:53,628][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 2629
[2016-09-14 20:46:53,629][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 20:46:53,629][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:46:56,637][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 20:46:56,638][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 20:46:56,738][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 20:46:57,139][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:46:57,139][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 20:46:57,141][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 2630) with member_id kafka-python-1.3.1-13e231a2-cab1-4ece-9aaa-7f8f30cc4b6a
[2016-09-14 20:46:57,143][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 2630
[2016-09-14 20:46:57,144][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 20:46:57,144][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:00,154][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 20:47:00,154][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 20:47:00,255][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 20:47:00,655][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:00,655][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 20:47:00,655][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 2631) with member_id kafka-python-1.3.1-13e231a2-cab1-4ece-9aaa-7f8f30cc4b6a
[2016-09-14 20:47:00,657][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 2631
[2016-09-14 20:47:00,657][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 20:47:00,657][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:03,667][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 20:47:03,667][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 20:47:03,768][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 20:47:04,168][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:04,168][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 20:47:04,169][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 2632) with member_id kafka-python-1.3.1-13e231a2-cab1-4ece-9aaa-7f8f30cc4b6a
[2016-09-14 20:47:04,170][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 2632
[2016-09-14 20:47:04,170][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 20:47:04,170][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:07,177][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 20:47:07,177][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 20:47:07,278][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 20:47:07,679][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:07,679][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 20:47:07,683][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 2633) with member_id kafka-python-1.3.1-13e231a2-cab1-4ece-9aaa-7f8f30cc4b6a
[2016-09-14 20:47:07,683][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 20:47:11,192][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 2634) with member_id kafka-python-1.3.1-13e231a2-cab1-4ece-9aaa-7f8f30cc4b6a
[2016-09-14 20:47:11,193][kafka.coordinator.consumer][WARNING]Auto offset commit failed for group kafka-python-default-group: CommitFailedError: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured session.timeout.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
[2016-09-14 20:47:11,193][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 2634
[2016-09-14 20:47:11,194][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 20:47:11,194][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:14,201][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 20:47:14,201][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 20:47:14,302][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 20:47:14,702][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:14,702][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 20:47:14,705][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 2635) with member_id kafka-python-1.3.1-13e231a2-cab1-4ece-9aaa-7f8f30cc4b6a
[2016-09-14 20:47:14,713][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 2635
[2016-09-14 20:47:14,713][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 20:47:14,713][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:17,720][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 20:47:17,720][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 20:47:17,821][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 20:47:18,221][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:18,221][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 20:47:18,225][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 2636) with member_id kafka-python-1.3.1-13e231a2-cab1-4ece-9aaa-7f8f30cc4b6a
[2016-09-14 20:47:18,229][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 2636
[2016-09-14 20:47:18,230][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 20:47:18,230][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:21,237][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 20:47:21,237][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 20:47:21,338][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 20:47:21,738][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:21,739][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 20:47:21,741][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 2637) with member_id kafka-python-1.3.1-13e231a2-cab1-4ece-9aaa-7f8f30cc4b6a
[2016-09-14 20:47:21,741][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 2637
[2016-09-14 20:47:21,741][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 20:47:21,741][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:24,752][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 20:47:24,752][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 20:47:24,853][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 20:47:25,254][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:25,254][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 20:47:25,255][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 2638) with member_id kafka-python-1.3.1-13e231a2-cab1-4ece-9aaa-7f8f30cc4b6a
[2016-09-14 20:47:25,256][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 2638
[2016-09-14 20:47:25,257][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 20:47:25,257][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:28,269][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 20:47:28,269][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 20:47:28,370][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 20:47:28,769][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:28,769][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 20:47:28,770][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 2639) with member_id kafka-python-1.3.1-13e231a2-cab1-4ece-9aaa-7f8f30cc4b6a
[2016-09-14 20:47:28,774][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 2639
[2016-09-14 20:47:28,775][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 20:47:28,775][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:31,781][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 20:47:31,781][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 20:47:31,882][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 20:47:32,282][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:32,282][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 20:47:32,285][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 2640) with member_id kafka-python-1.3.1-13e231a2-cab1-4ece-9aaa-7f8f30cc4b6a
[2016-09-14 20:47:32,286][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 2640
[2016-09-14 20:47:32,286][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 20:47:32,286][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:35,292][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 20:47:35,293][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 20:47:35,395][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 20:47:35,794][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:35,794][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 20:47:35,800][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 2641) with member_id kafka-python-1.3.1-13e231a2-cab1-4ece-9aaa-7f8f30cc4b6a
[2016-09-14 20:47:35,804][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 20:47:39,319][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 2642) with member_id kafka-python-1.3.1-13e231a2-cab1-4ece-9aaa-7f8f30cc4b6a
[2016-09-14 20:47:39,319][kafka.coordinator.consumer][WARNING]Auto offset commit failed for group kafka-python-default-group: CommitFailedError: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured session.timeout.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
[2016-09-14 20:47:39,321][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 2642
[2016-09-14 20:47:39,321][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 20:47:39,321][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:42,329][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 20:47:42,329][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 20:47:42,429][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 20:47:42,830][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:42,830][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 20:47:42,835][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 2643) with member_id kafka-python-1.3.1-13e231a2-cab1-4ece-9aaa-7f8f30cc4b6a
[2016-09-14 20:47:42,836][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 2643
[2016-09-14 20:47:42,837][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 20:47:42,837][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:45,842][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 20:47:45,842][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 20:47:45,943][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 20:47:46,344][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 20:47:46,344][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 20:47:46,344][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 2644) with member_id kafka-python-1.3.1-13e231a2-cab1-4ece-9aaa-7f8f30cc4b6a
[2016-09-14 20:47:46,347][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 2644
[2016-09-14 20:47:46,348][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 20:47:46,348][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
