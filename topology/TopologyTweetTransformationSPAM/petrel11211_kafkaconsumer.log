Beginning task setup

/usr/bin/flock
Using existing venv: /tmp/petrel-spam-5-1473800596/venv
Task setup took 0 seconds
Launching: python -m petrel.run kafkaconsumer /home/pipe/topology/TopologyTweetTransformationSPAM/petrel11211_kafkaconsumer.log
/usr/local/lib/python2.7/dist-packages/petrel-1.0.1.0.3-py2.7.egg/petrel/run.py invoked with the following arguments: ['kafkaconsumer', '/home/pipe/topology/TopologyTweetTransformationSPAM/petrel11211_kafkaconsumer.log']
python version: 2.7.12
user=root
PATH=/tmp/petrel-spam-5-1473800596/venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin
LD_LIBRARY_PATH=/home/apache-storm-1.0.1/data/supervisor/stormdist/spam-5-1473800596/resources/Linux-amd64:/home/apache-storm-1.0.1/data/supervisor/stormdist/spam-5-1473800596/resources:/usr/local/lib:/opt/local/lib:/usr/lib
PYTHON_EGG_CACHE=/tmp/petrel-spam-5-1473800596/egg_cache
[2016-09-14 00:13:42,391][storm][INFO]Tuple profiling enabled. Will log tuple processing times.
[2016-09-14 00:13:42,551][storm][INFO]Task received setupInfo from Storm: {'pidDir': '/home/apache-storm-1.0.1/data/workers/91abd642-53f8-43b1-bf73-e74a1b9da7e5/pids', 'conf': {'storm.group.mapping.service.params': None, 'topology.tuple.serializer': 'org.apache.storm.serialization.types.ListDelegateSerializer', 'topology.workers': 1, 'drpc.worker.threads': 64, 'ui.filter.params': None, 'transactional.zookeeper.root': '/transactional', 'logviewer.cleanup.age.mins': 10080, 'worker.profiler.command': 'flight.bash', 'topology.executor.send.buffer.size': 1024, 'nimbus.file.copy.expiration.secs': 600, 'oauth.acess_token': ' 702208758362087425-HZiyl1x7Bh98cQa1WLBDYylyu10Bpl7', 'drpc.childopts': '-Xmx768m', 'nimbus.thrift.port': 6627, 'topology.disruptor.wait.timeout.millis': 1000, 'storm.zookeeper.retry.intervalceiling.millis': 30000, 'storm.local.dir': '/home/apache-storm-1.0.1/data', 'storm.auth.simple-acl.users': [], 'drpc.invocations.threads': 64, 'storm.zookeeper.superACL': None, 'storm.cluster.state.store': 'org.apache.storm.cluster_state.zookeeper_state_factory', 'storm.codedistributor.class': 'org.apache.storm.codedistributor.LocalFileSystemCodeDistributor', 'drpc.https.keystore.password': '', 'supervisor.blobstore.download.max_retries': 3, 'pacemaker.kerberos.users': [], 'storm.messaging.netty.client_worker_threads': 1, 'oauth.consumer_secret': 'ADf76fi3O1lKMzBxWnjqf93l3GHv28uar3bkblkvyBrAyoA23i', 'topology.component.resources.offheap.memory.mb': 0.0, 'supervisor.heartbeat.frequency.secs': 5, 'storm.group.mapping.service.cache.duration.secs': 120, 'storm.group.mapping.service': 'org.apache.storm.security.auth.ShellBasedGroupsMapping', 'storm.workers.artifacts.dir': 'workers-artifacts', 'drpc.request.timeout.secs': 600, 'pacemaker.childopts': '-Xmx1024m', 'nimbus.seeds': ['localhost'], 'topology.shellbolt.max.pending': 100, 'topology.min.replication.count': 1, 'topology.skip.missing.kryo.registrations': False, 'worker.heartbeat.frequency.secs': 1, 'storm.auth.simple-acl.users.commands': [], 'storm.zookepeer.port': 2181, 'zmq.hwm': 0, 'topology.worker.shared.thread.pool.size': 4, 'storm.zookeeper.connection.timeout': 15000, 'java.library.path': '/usr/local/lib:/opt/local/lib:/usr/lib', 'logviewer.max.sum.worker.logs.size.mb': 4096, 'task.refresh.poll.secs': 10, 'topology.max.error.report.per.interval': 5, 'topology.worker.logwriter.childopts': '-Xmx64m', 'ui.actions.enabled': True, 'storm.health.check.timeout.ms': 5000, 'topology.scheduler.strategy': 'org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy', 'ui.host': '0.0.0.0', 'storm.messaging.netty.server_worker_threads': 1, 'topology.disruptor.batch.size': 100, 'storm.id': 'spam-5-1473800596', 'supervisor.worker.start.timeout.secs': 120, 'zmq.threads': 1, 'topology.acker.executors': None, 'pacemaker.thread.timeout': 10, 'storm.local.mode.zmq': False, 'topology.eventlogger.executors': 0, 'topology.tick.tuple.freq.secs': 30, 'supervisor.memory.capacity.mb': 3072.0, 'supervisor.worker.shutdown.sleep.secs': 1, 'pacemaker.base.threads': 10, 'drpc.http.creds.plugin': 'org.apache.storm.security.auth.DefaultHttpCredentialsPlugin', 'storm.zookeeper.servers': ['localhost'], 'supervisor.localizer.cache.target.size.mb': 10240, 'storm.messaging.netty.transfer.batch.size': 262144, 'resource.aware.scheduler.eviction.strategy': 'org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy', 'topology.environment': None, 'storm.zookeeper.port': 2181, 'storm.auth.simple-acl.admins': [], 'pacemaker.host': 'localhost', 'nimbus.childopts': '-Xmx1024m', 'storm.principal.tolocal': 'org.apache.storm.security.auth.DefaultPrincipalToLocal', 'storm.nimbus.retry.times': 5, 'topology.classpath': None, 'drpc.authorizer.acl.filename': 'drpc-auth-acl.yaml', 'topology.bolts.outgoing.overflow.buffer.enable': False, 'nimbus.credential.renewers.freq.secs': 600, 'worker.childopts': '-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump', 'drpc.queue.size': 128, 'supervisor.blobstore.class': 'org.apache.storm.blobstore.NimbusBlobStore', 'topology.multilang.serializer': 'org.apache.storm.multilang.JsonSerializer', 'storm.zookeeper.retry.times': 5, 'topology.disable.loadaware': False, 'supervisor.run.worker.as.user': False, 'storm.blobstore.replication.factor': 3, 'worker.profiler.childopts': '-XX:+UnlockCommercialFeatures -XX:+FlightRecorder', 'nimbus.thrift.threads': 64, 'nimbus.monitor.freq.secs': 10, 'storm.blobstore.inputstream.buffer.size.bytes': 65536, 'dev.zookeeper.path': '/tmp/dev-storm-zookeeper', 'topology.users': [], 'storm.daemon.metrics.reporter.plugins': ['org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter'], 'storm.exhibitor.poll.uripath': '/exhibitor/v1/cluster/list', 'pacemaker.max.threads': 50, 'drpc.https.keystore.type': 'JKS', 'topology.tasks': None, 'storm.zookeeper.root': '/storm', 'logviewer.childopts': '-Xmx128m', 'topology.max.replication.wait.time.sec': 60, 'worker.gc.childopts': '', 'backpressure.disruptor.low.watermark': 0.4, 'storm.meta.serialization.delegate': 'org.apache.storm.serialization.GzipThriftSerializationDelegate', 'transactional.zookeeper.port': None, 'drpc.max_buffer_size': 1048576, 'topology.worker.childopts': None, 'storm.auth.simple-white-list.users': [], 'topology.max.spout.pending': None, 'nimbus.topology.validator': 'org.apache.storm.nimbus.DefaultTopologyValidator', 'topology.kryo.register': None, 'petrel.host': 'localhost', 'client.blobstore.class': 'org.apache.storm.blobstore.NimbusBlobStore', 'nimbus.cleanup.inbox.freq.secs': 600, 'storm.nimbus.retry.intervalceiling.millis': 60000, 'storm.network.topography.plugin': 'org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping', 'storm.messaging.netty.min_wait_ms': 100, 'nimbus.task.timeout.secs': 30, 'topology.disruptor.batch.timeout.millis': 1, 'topology.state.checkpoint.interval.ms': 1000, 'ui.header.buffer.bytes': 4096, 'nimbus.thrift.max_buffer_size': 1048576, 'ui.http.creds.plugin': 'org.apache.storm.security.auth.DefaultHttpCredentialsPlugin', 'topology.sleep.spout.wait.strategy.time.ms': 1, 'nimbus.blobstore.expiration.secs': 600, 'storm.cluster.mode': 'distributed', 'storm.messaging.netty.socket.backlog': 500, 'worker.profiler.enabled': False, 'nimbus.queue.size': 100000, 'logviewer.appender.name': 'A1', 'drpc.authorizer.acl.strict': False, 'ui.port': 8080, 'supervisor.slots.ports': [6700, 6701, 6702, 6703], 'worker.log.level.reset.poll.secs': 30, 'storm.nimbus.retry.interval.millis': 2000, 'drpc.invocations.port': 3773, 'supervisor.monitor.frequency.secs': 3, 'ui.childopts': '-Xmx768m', 'transactional.zookeeper.servers': None, 'storm.log4j2.conf.dir': 'log4j2', 'supervisor.supervisors': [], 'zmq.linger.millis': 5000, 'topology.error.throttle.interval.secs': 10, 'storm.health.check.dir': 'healthchecks', 'topology.executor.receive.buffer.size': 1024, 'nimbus.impersonation.authorizer': 'org.apache.storm.security.auth.authorizer.ImpersonationAuthorizer', 'topology.submitter.principal': '', 'topology.worker.max.heap.size.mb': 768.0, 'topology.spout.wait.strategy': 'org.apache.storm.spout.SleepSpoutWaitStrategy', 'task.heartbeat.frequency.secs': 3, 'topology.transfer.buffer.size': 1024, 'storm.zookeeper.session.timeout': 20000, 'topology.testing.always.try.serialize': False, 'nimbus.blobstore.class': 'org.apache.storm.blobstore.LocalFsBlobStore', 'topology.stats.sample.rate': 0.05, 'topology.fall.back.on.java.serialization': True, 'storm.exhibitor.port': 8080, 'storm.zookeeper.auth.password': None, 'supervisor.childopts': '-Xmx256m', 'topology.backpressure.enable': True, 'pacemaker.port': 6699, 'topology.enable.message.timeouts': True, 'nimbus.code.sync.freq.secs': 120, 'backpressure.disruptor.high.watermark': 0.9, 'storm.messaging.netty.max_wait_ms': 1000, 'topology.worker.receiver.thread.count': 1, 'topology.component.resources.onheap.memory.mb': 128.0, 'resource.aware.scheduler.priority.strategy': 'org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy', 'nimbus.supervisor.timeout.secs': 60, 'pacemaker.auth.method': 'NONE', 'drpc.https.port': -1, 'nimbus.inbox.jar.expiration.secs': 3600, 'scheduler.display.resource': False, 'topology.kryo.factory': 'org.apache.storm.serialization.DefaultKryoFactory', 'storm.zookeeper.retry.interval': 1000, 'supervisor.supervisors.commands': [], 'supervisor.localizer.cleanup.interval.ms': 600000, 'storm.messaging.netty.max_retries': 300, 'task.credentials.poll.secs': 30, 'drpc.http.port': 3774, 'storm.messaging.transport': 'org.apache.storm.messaging.netty.Context', 'supervisor.enable': True, 'nimbus.task.launch.secs': 120, 'supervisor.blobstore.download.thread.count': 5, 'topology.message.timeout.secs': 30, 'oauth.acess_token_secret': 'IiNOTfgE3tEZvW2HDQhRKPMoOLU43NXJCXk8maj51SdAT', 'storm.messaging.netty.authentication': False, 'petrel.user': 'pipe', 'drpc.port': 3772, 'storm.messaging.netty.buffer_size': 5242880, 'topology.state.synchronization.timeout.secs': 60, 'worker.heap.memory.mb': 768, 'topology.name': 'spam', 'topology.priority': 29, 'supervisor.worker.timeout.secs': 30, 'ui.filter': None, 'topology.trident.batch.emit.interval.millis': 500, 'topology.max.task.parallelism': None, 'supervisor.cpu.capacity': 400.0, 'topology.submitter.user': 'root', 'logviewer.max.per.worker.logs.size.mb': 2048, 'nimbus.host': 'localhost', 'topology.builtin.metrics.bucket.size.secs': 60, 'topology.component.cpu.pcore.percent': 10.0, 'ui.users': None, 'storm.thrift.transport': 'org.apache.storm.security.auth.SimpleTransportPlugin', 'logs.users': None, 'logviewer.port': 8000, 'oauth.consumer_key': 'eaFmBSxUveRJfmyZYeabti9Q9', 'topology.kryo.decorators': [], 'topology.debug': False, 'storm.zookeeper.auth.user': None}, 'context': {'task->component': {'11': '__acker', '10': 'WordDivider', '1': 'CountThreeWords', '3': 'CountTwoWords', '2': 'CountThreeWords', '5': 'CountWord', '4': 'CountTwoWords', '7': 'KafkaConsumer', '6': 'CountWord', '9': 'TwoWordDivider', '8': 'ThreeWordDivider'}, 'stream->target->grouping': {'default': {'WordDivider': {'type': 'SHUFFLE'}, 'ThreeWordDivider': {'type': 'SHUFFLE'}, 'TwoWordDivider': {'type': 'SHUFFLE'}}}, 'source->stream->fields': {}, 'streams': ['default'], 'stream->outputfields': {'default': ['sentence', 'user']}, 'taskid': 7, 'source->stream->grouping': {}, 'componentid': 'KafkaConsumer'}}
[2016-09-14 00:13:42,562][storm][INFO]Task sent pid to Storm
[2016-09-14 00:13:42,673][kafka.conn][INFO]Broker version identifed as 0.10
[2016-09-14 00:13:42,673][kafka.conn][INFO]Set configuration api_version=(0, 10) to skip auto check_version requests on startup
[2016-09-14 00:13:42,675][kafka.consumer.subscription_state][INFO]Updating subscribed topics to: ['spamtopic']
[2016-09-14 00:13:42,676][kafka.cluster][INFO]Group coordinator for kafka-python-default-group is BrokerMetadata(nodeId=0, host=u'localhost', port=9092, rack=None)
[2016-09-14 00:13:42,676][kafka.coordinator][INFO]Discovered coordinator 0 for group kafka-python-default-group
[2016-09-14 00:13:42,677][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([]) for group kafka-python-default-group
[2016-09-14 00:13:42,677][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:14:06,605][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 302) with member_id kafka-python-1.3.1-e2dd7a0f-4f14-45b5-9590-6c20ba62b61b
[2016-09-14 00:14:06,606][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 302
[2016-09-14 00:14:06,607][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:14:06,607][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:09,619][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:14:09,619][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:14:09,721][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:14:10,121][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:10,122][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:14:10,123][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 303) with member_id kafka-python-1.3.1-e2dd7a0f-4f14-45b5-9590-6c20ba62b61b
[2016-09-14 00:14:10,127][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 303
[2016-09-14 00:14:10,128][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:14:10,128][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:13,136][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:14:13,136][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:14:13,237][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:14:13,638][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:13,638][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:14:13,640][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 304) with member_id kafka-python-1.3.1-e2dd7a0f-4f14-45b5-9590-6c20ba62b61b
[2016-09-14 00:14:13,642][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 304
[2016-09-14 00:14:13,642][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:14:13,642][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:16,651][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:14:16,652][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:14:16,753][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:14:17,153][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:17,153][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:14:17,161][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 305) with member_id kafka-python-1.3.1-e2dd7a0f-4f14-45b5-9590-6c20ba62b61b
[2016-09-14 00:14:17,162][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:14:20,672][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 306) with member_id kafka-python-1.3.1-e2dd7a0f-4f14-45b5-9590-6c20ba62b61b
[2016-09-14 00:14:20,673][kafka.coordinator.consumer][WARNING]Auto offset commit failed for group kafka-python-default-group: CommitFailedError: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured session.timeout.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
[2016-09-14 00:14:20,676][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 306
[2016-09-14 00:14:20,676][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:14:20,676][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:23,685][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:14:23,685][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:14:23,787][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:14:24,187][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:24,187][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:14:24,191][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 307) with member_id kafka-python-1.3.1-e2dd7a0f-4f14-45b5-9590-6c20ba62b61b
[2016-09-14 00:14:24,192][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 307
[2016-09-14 00:14:24,193][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:14:24,193][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:27,203][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:14:27,203][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:14:27,305][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:14:27,706][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:27,706][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:14:27,707][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 308) with member_id kafka-python-1.3.1-e2dd7a0f-4f14-45b5-9590-6c20ba62b61b
[2016-09-14 00:14:27,709][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 308
[2016-09-14 00:14:27,710][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:14:27,710][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:30,719][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:14:30,719][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:14:30,820][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:14:31,220][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:31,221][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:14:31,225][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 309) with member_id kafka-python-1.3.1-e2dd7a0f-4f14-45b5-9590-6c20ba62b61b
[2016-09-14 00:14:31,226][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 309
[2016-09-14 00:14:31,226][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:14:31,227][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:34,237][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:14:34,237][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:14:34,338][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:14:34,740][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:34,740][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:14:34,744][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 310) with member_id kafka-python-1.3.1-e2dd7a0f-4f14-45b5-9590-6c20ba62b61b
[2016-09-14 00:14:34,753][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:14:38,262][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 311) with member_id kafka-python-1.3.1-e2dd7a0f-4f14-45b5-9590-6c20ba62b61b
[2016-09-14 00:14:38,263][kafka.coordinator.consumer][WARNING]Auto offset commit failed for group kafka-python-default-group: CommitFailedError: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured session.timeout.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
[2016-09-14 00:14:38,267][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 311
[2016-09-14 00:14:38,268][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:14:38,268][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:41,279][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:14:41,279][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:14:41,380][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:14:41,780][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:41,780][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:14:41,781][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 312) with member_id kafka-python-1.3.1-e2dd7a0f-4f14-45b5-9590-6c20ba62b61b
[2016-09-14 00:14:41,784][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 312
[2016-09-14 00:14:41,784][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:14:41,785][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:44,794][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:14:44,794][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:14:44,895][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:14:45,296][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:45,297][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:14:45,298][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 313) with member_id kafka-python-1.3.1-e2dd7a0f-4f14-45b5-9590-6c20ba62b61b
[2016-09-14 00:14:45,301][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 313
[2016-09-14 00:14:45,301][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:14:45,301][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:48,314][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:14:48,314][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:14:48,415][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:14:48,815][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:48,816][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:14:48,819][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 314) with member_id kafka-python-1.3.1-e2dd7a0f-4f14-45b5-9590-6c20ba62b61b
[2016-09-14 00:14:48,822][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 314
[2016-09-14 00:14:48,823][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:14:48,823][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:51,832][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:14:51,833][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:14:51,934][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:14:52,334][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:52,335][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:14:52,336][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 315) with member_id kafka-python-1.3.1-e2dd7a0f-4f14-45b5-9590-6c20ba62b61b
[2016-09-14 00:14:52,338][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 315
[2016-09-14 00:14:52,338][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:14:52,338][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:55,349][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:14:55,349][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:14:55,450][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:14:55,851][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:55,851][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:14:55,854][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 316) with member_id kafka-python-1.3.1-e2dd7a0f-4f14-45b5-9590-6c20ba62b61b
[2016-09-14 00:14:55,856][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 316
[2016-09-14 00:14:55,856][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:14:55,856][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:58,865][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:14:58,865][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:14:58,966][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:14:59,367][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:14:59,368][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:14:59,372][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 317) with member_id kafka-python-1.3.1-e2dd7a0f-4f14-45b5-9590-6c20ba62b61b
[2016-09-14 00:14:59,374][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 317
[2016-09-14 00:14:59,374][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:14:59,374][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:15:02,384][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:15:02,385][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:15:02,486][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:15:02,886][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:15:02,887][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:15:02,888][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 318) with member_id kafka-python-1.3.1-e2dd7a0f-4f14-45b5-9590-6c20ba62b61b
[2016-09-14 00:15:02,890][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 318
[2016-09-14 00:15:02,890][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:15:02,890][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:15:05,899][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:15:05,899][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:15:06,001][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:15:06,402][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:15:06,402][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:15:06,408][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 319) with member_id kafka-python-1.3.1-e2dd7a0f-4f14-45b5-9590-6c20ba62b61b
[2016-09-14 00:15:06,409][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 319
[2016-09-14 00:15:06,409][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:15:06,409][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:15:09,419][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:15:09,419][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:15:09,520][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:15:09,921][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:15:09,921][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:15:09,923][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 320) with member_id kafka-python-1.3.1-e2dd7a0f-4f14-45b5-9590-6c20ba62b61b
[2016-09-14 00:15:09,926][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 320
[2016-09-14 00:15:09,926][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:15:09,926][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
