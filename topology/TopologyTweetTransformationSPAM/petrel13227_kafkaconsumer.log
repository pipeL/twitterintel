Beginning task setup

/usr/bin/flock
Using existing venv: /tmp/petrel-spam-5-1473800596/venv
Task setup took 0 seconds
Launching: python -m petrel.run kafkaconsumer /home/pipe/topology/TopologyTweetTransformationSPAM/petrel13227_kafkaconsumer.log
/usr/local/lib/python2.7/dist-packages/petrel-1.0.1.0.3-py2.7.egg/petrel/run.py invoked with the following arguments: ['kafkaconsumer', '/home/pipe/topology/TopologyTweetTransformationSPAM/petrel13227_kafkaconsumer.log']
python version: 2.7.12
user=root
PATH=/tmp/petrel-spam-5-1473800596/venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin
LD_LIBRARY_PATH=/home/apache-storm-1.0.1/data/supervisor/stormdist/spam-5-1473800596/resources/Linux-amd64:/home/apache-storm-1.0.1/data/supervisor/stormdist/spam-5-1473800596/resources:/usr/local/lib:/opt/local/lib:/usr/lib
PYTHON_EGG_CACHE=/tmp/petrel-spam-5-1473800596/egg_cache
[2016-09-14 00:39:42,277][storm][INFO]Tuple profiling enabled. Will log tuple processing times.
[2016-09-14 00:39:42,477][storm][INFO]Task received setupInfo from Storm: {'pidDir': '/home/apache-storm-1.0.1/data/workers/aa265699-55ad-49eb-8b0b-c70d1a3ac938/pids', 'conf': {'storm.group.mapping.service.params': None, 'topology.tuple.serializer': 'org.apache.storm.serialization.types.ListDelegateSerializer', 'topology.workers': 1, 'drpc.worker.threads': 64, 'ui.filter.params': None, 'transactional.zookeeper.root': '/transactional', 'logviewer.cleanup.age.mins': 10080, 'worker.profiler.command': 'flight.bash', 'topology.executor.send.buffer.size': 1024, 'nimbus.file.copy.expiration.secs': 600, 'oauth.acess_token': ' 702208758362087425-HZiyl1x7Bh98cQa1WLBDYylyu10Bpl7', 'drpc.childopts': '-Xmx768m', 'nimbus.thrift.port': 6627, 'topology.disruptor.wait.timeout.millis': 1000, 'storm.zookeeper.retry.intervalceiling.millis': 30000, 'storm.local.dir': '/home/apache-storm-1.0.1/data', 'storm.auth.simple-acl.users': [], 'drpc.invocations.threads': 64, 'storm.zookeeper.superACL': None, 'storm.cluster.state.store': 'org.apache.storm.cluster_state.zookeeper_state_factory', 'storm.codedistributor.class': 'org.apache.storm.codedistributor.LocalFileSystemCodeDistributor', 'drpc.https.keystore.password': '', 'supervisor.blobstore.download.max_retries': 3, 'pacemaker.kerberos.users': [], 'storm.messaging.netty.client_worker_threads': 1, 'oauth.consumer_secret': 'ADf76fi3O1lKMzBxWnjqf93l3GHv28uar3bkblkvyBrAyoA23i', 'topology.component.resources.offheap.memory.mb': 0.0, 'supervisor.heartbeat.frequency.secs': 5, 'storm.group.mapping.service.cache.duration.secs': 120, 'storm.group.mapping.service': 'org.apache.storm.security.auth.ShellBasedGroupsMapping', 'storm.workers.artifacts.dir': 'workers-artifacts', 'drpc.request.timeout.secs': 600, 'pacemaker.childopts': '-Xmx1024m', 'nimbus.seeds': ['localhost'], 'topology.shellbolt.max.pending': 100, 'topology.min.replication.count': 1, 'topology.skip.missing.kryo.registrations': False, 'worker.heartbeat.frequency.secs': 1, 'storm.auth.simple-acl.users.commands': [], 'storm.zookepeer.port': 2181, 'zmq.hwm': 0, 'topology.worker.shared.thread.pool.size': 4, 'storm.zookeeper.connection.timeout': 15000, 'java.library.path': '/usr/local/lib:/opt/local/lib:/usr/lib', 'logviewer.max.sum.worker.logs.size.mb': 4096, 'task.refresh.poll.secs': 10, 'topology.max.error.report.per.interval': 5, 'topology.worker.logwriter.childopts': '-Xmx64m', 'ui.actions.enabled': True, 'storm.health.check.timeout.ms': 5000, 'topology.scheduler.strategy': 'org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy', 'ui.host': '0.0.0.0', 'storm.messaging.netty.server_worker_threads': 1, 'topology.disruptor.batch.size': 100, 'storm.id': 'spam-5-1473800596', 'supervisor.worker.start.timeout.secs': 120, 'zmq.threads': 1, 'topology.acker.executors': None, 'pacemaker.thread.timeout': 10, 'storm.local.mode.zmq': False, 'topology.eventlogger.executors': 0, 'topology.tick.tuple.freq.secs': 30, 'supervisor.memory.capacity.mb': 3072.0, 'supervisor.worker.shutdown.sleep.secs': 1, 'pacemaker.base.threads': 10, 'drpc.http.creds.plugin': 'org.apache.storm.security.auth.DefaultHttpCredentialsPlugin', 'storm.zookeeper.servers': ['localhost'], 'supervisor.localizer.cache.target.size.mb': 10240, 'storm.messaging.netty.transfer.batch.size': 262144, 'resource.aware.scheduler.eviction.strategy': 'org.apache.storm.scheduler.resource.strategies.eviction.DefaultEvictionStrategy', 'topology.environment': None, 'storm.zookeeper.port': 2181, 'storm.auth.simple-acl.admins': [], 'pacemaker.host': 'localhost', 'nimbus.childopts': '-Xmx1024m', 'storm.principal.tolocal': 'org.apache.storm.security.auth.DefaultPrincipalToLocal', 'storm.nimbus.retry.times': 5, 'topology.classpath': None, 'drpc.authorizer.acl.filename': 'drpc-auth-acl.yaml', 'topology.bolts.outgoing.overflow.buffer.enable': False, 'nimbus.credential.renewers.freq.secs': 600, 'worker.childopts': '-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump', 'drpc.queue.size': 128, 'supervisor.blobstore.class': 'org.apache.storm.blobstore.NimbusBlobStore', 'topology.multilang.serializer': 'org.apache.storm.multilang.JsonSerializer', 'storm.zookeeper.retry.times': 5, 'topology.disable.loadaware': False, 'supervisor.run.worker.as.user': False, 'storm.blobstore.replication.factor': 3, 'worker.profiler.childopts': '-XX:+UnlockCommercialFeatures -XX:+FlightRecorder', 'nimbus.thrift.threads': 64, 'nimbus.monitor.freq.secs': 10, 'storm.blobstore.inputstream.buffer.size.bytes': 65536, 'dev.zookeeper.path': '/tmp/dev-storm-zookeeper', 'topology.users': [], 'storm.daemon.metrics.reporter.plugins': ['org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter'], 'storm.exhibitor.poll.uripath': '/exhibitor/v1/cluster/list', 'pacemaker.max.threads': 50, 'drpc.https.keystore.type': 'JKS', 'topology.tasks': None, 'storm.zookeeper.root': '/storm', 'logviewer.childopts': '-Xmx128m', 'topology.max.replication.wait.time.sec': 60, 'worker.gc.childopts': '', 'backpressure.disruptor.low.watermark': 0.4, 'storm.meta.serialization.delegate': 'org.apache.storm.serialization.GzipThriftSerializationDelegate', 'transactional.zookeeper.port': None, 'drpc.max_buffer_size': 1048576, 'topology.worker.childopts': None, 'storm.auth.simple-white-list.users': [], 'topology.max.spout.pending': None, 'nimbus.topology.validator': 'org.apache.storm.nimbus.DefaultTopologyValidator', 'topology.kryo.register': None, 'petrel.host': 'localhost', 'client.blobstore.class': 'org.apache.storm.blobstore.NimbusBlobStore', 'nimbus.cleanup.inbox.freq.secs': 600, 'storm.nimbus.retry.intervalceiling.millis': 60000, 'storm.network.topography.plugin': 'org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping', 'storm.messaging.netty.min_wait_ms': 100, 'nimbus.task.timeout.secs': 30, 'topology.disruptor.batch.timeout.millis': 1, 'topology.state.checkpoint.interval.ms': 1000, 'ui.header.buffer.bytes': 4096, 'nimbus.thrift.max_buffer_size': 1048576, 'ui.http.creds.plugin': 'org.apache.storm.security.auth.DefaultHttpCredentialsPlugin', 'topology.sleep.spout.wait.strategy.time.ms': 1, 'nimbus.blobstore.expiration.secs': 600, 'storm.cluster.mode': 'distributed', 'storm.messaging.netty.socket.backlog': 500, 'worker.profiler.enabled': False, 'nimbus.queue.size': 100000, 'logviewer.appender.name': 'A1', 'drpc.authorizer.acl.strict': False, 'ui.port': 8080, 'supervisor.slots.ports': [6700, 6701, 6702, 6703], 'worker.log.level.reset.poll.secs': 30, 'storm.nimbus.retry.interval.millis': 2000, 'drpc.invocations.port': 3773, 'supervisor.monitor.frequency.secs': 3, 'ui.childopts': '-Xmx768m', 'transactional.zookeeper.servers': None, 'storm.log4j2.conf.dir': 'log4j2', 'supervisor.supervisors': [], 'zmq.linger.millis': 5000, 'topology.error.throttle.interval.secs': 10, 'storm.health.check.dir': 'healthchecks', 'topology.executor.receive.buffer.size': 1024, 'nimbus.impersonation.authorizer': 'org.apache.storm.security.auth.authorizer.ImpersonationAuthorizer', 'topology.submitter.principal': '', 'topology.worker.max.heap.size.mb': 768.0, 'topology.spout.wait.strategy': 'org.apache.storm.spout.SleepSpoutWaitStrategy', 'task.heartbeat.frequency.secs': 3, 'topology.transfer.buffer.size': 1024, 'storm.zookeeper.session.timeout': 20000, 'topology.testing.always.try.serialize': False, 'nimbus.blobstore.class': 'org.apache.storm.blobstore.LocalFsBlobStore', 'topology.stats.sample.rate': 0.05, 'topology.fall.back.on.java.serialization': True, 'storm.exhibitor.port': 8080, 'storm.zookeeper.auth.password': None, 'supervisor.childopts': '-Xmx256m', 'topology.backpressure.enable': True, 'pacemaker.port': 6699, 'topology.enable.message.timeouts': True, 'nimbus.code.sync.freq.secs': 120, 'backpressure.disruptor.high.watermark': 0.9, 'storm.messaging.netty.max_wait_ms': 1000, 'topology.worker.receiver.thread.count': 1, 'topology.component.resources.onheap.memory.mb': 128.0, 'resource.aware.scheduler.priority.strategy': 'org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy', 'nimbus.supervisor.timeout.secs': 60, 'pacemaker.auth.method': 'NONE', 'drpc.https.port': -1, 'nimbus.inbox.jar.expiration.secs': 3600, 'scheduler.display.resource': False, 'topology.kryo.factory': 'org.apache.storm.serialization.DefaultKryoFactory', 'storm.zookeeper.retry.interval': 1000, 'supervisor.supervisors.commands': [], 'supervisor.localizer.cleanup.interval.ms': 600000, 'storm.messaging.netty.max_retries': 300, 'task.credentials.poll.secs': 30, 'drpc.http.port': 3774, 'storm.messaging.transport': 'org.apache.storm.messaging.netty.Context', 'supervisor.enable': True, 'nimbus.task.launch.secs': 120, 'supervisor.blobstore.download.thread.count': 5, 'topology.message.timeout.secs': 30, 'oauth.acess_token_secret': 'IiNOTfgE3tEZvW2HDQhRKPMoOLU43NXJCXk8maj51SdAT', 'storm.messaging.netty.authentication': False, 'petrel.user': 'pipe', 'drpc.port': 3772, 'storm.messaging.netty.buffer_size': 5242880, 'topology.state.synchronization.timeout.secs': 60, 'worker.heap.memory.mb': 768, 'topology.name': 'spam', 'topology.priority': 29, 'supervisor.worker.timeout.secs': 30, 'ui.filter': None, 'topology.trident.batch.emit.interval.millis': 500, 'topology.max.task.parallelism': None, 'supervisor.cpu.capacity': 400.0, 'topology.submitter.user': 'root', 'logviewer.max.per.worker.logs.size.mb': 2048, 'nimbus.host': 'localhost', 'topology.builtin.metrics.bucket.size.secs': 60, 'topology.component.cpu.pcore.percent': 10.0, 'ui.users': None, 'storm.thrift.transport': 'org.apache.storm.security.auth.SimpleTransportPlugin', 'logs.users': None, 'logviewer.port': 8000, 'oauth.consumer_key': 'eaFmBSxUveRJfmyZYeabti9Q9', 'topology.kryo.decorators': [], 'topology.debug': False, 'storm.zookeeper.auth.user': None}, 'context': {'task->component': {'11': '__acker', '10': 'WordDivider', '1': 'CountThreeWords', '3': 'CountTwoWords', '2': 'CountThreeWords', '5': 'CountWord', '4': 'CountTwoWords', '7': 'KafkaConsumer', '6': 'CountWord', '9': 'TwoWordDivider', '8': 'ThreeWordDivider'}, 'stream->target->grouping': {'default': {'WordDivider': {'type': 'SHUFFLE'}, 'ThreeWordDivider': {'type': 'SHUFFLE'}, 'TwoWordDivider': {'type': 'SHUFFLE'}}}, 'source->stream->fields': {}, 'streams': ['default'], 'stream->outputfields': {'default': ['sentence', 'user']}, 'taskid': 7, 'source->stream->grouping': {}, 'componentid': 'KafkaConsumer'}}
[2016-09-14 00:39:42,485][storm][INFO]Task sent pid to Storm
[2016-09-14 00:39:42,601][kafka.conn][INFO]Broker version identifed as 0.10
[2016-09-14 00:39:42,601][kafka.conn][INFO]Set configuration api_version=(0, 10) to skip auto check_version requests on startup
[2016-09-14 00:39:42,620][kafka.consumer.subscription_state][INFO]Updating subscribed topics to: ['spamtopic']
[2016-09-14 00:39:42,622][kafka.cluster][INFO]Group coordinator for kafka-python-default-group is BrokerMetadata(nodeId=0, host=u'localhost', port=9092, rack=None)
[2016-09-14 00:39:42,622][kafka.coordinator][INFO]Discovered coordinator 0 for group kafka-python-default-group
[2016-09-14 00:39:42,623][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([]) for group kafka-python-default-group
[2016-09-14 00:39:42,623][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:40:06,275][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 355) with member_id kafka-python-1.3.1-21d03dd0-a3c0-488f-a144-8fe57e7af7eb
[2016-09-14 00:40:06,285][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 355
[2016-09-14 00:40:06,285][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:40:06,285][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:09,305][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:40:09,305][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:40:09,406][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:40:09,807][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:09,807][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:40:09,810][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 356) with member_id kafka-python-1.3.1-21d03dd0-a3c0-488f-a144-8fe57e7af7eb
[2016-09-14 00:40:09,812][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 356
[2016-09-14 00:40:09,812][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:40:09,813][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:12,822][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:40:12,822][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:40:12,924][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:40:13,325][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:13,325][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:40:13,330][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 357) with member_id kafka-python-1.3.1-21d03dd0-a3c0-488f-a144-8fe57e7af7eb
[2016-09-14 00:40:13,335][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 357
[2016-09-14 00:40:13,335][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:40:13,335][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:16,346][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:40:16,346][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:40:16,447][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:40:16,847][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:16,847][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:40:16,850][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 358) with member_id kafka-python-1.3.1-21d03dd0-a3c0-488f-a144-8fe57e7af7eb
[2016-09-14 00:40:16,852][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 358
[2016-09-14 00:40:16,852][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:40:16,852][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:19,862][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:40:19,863][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:40:19,964][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:40:20,365][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:20,365][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:40:20,366][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 359) with member_id kafka-python-1.3.1-21d03dd0-a3c0-488f-a144-8fe57e7af7eb
[2016-09-14 00:40:20,368][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 359
[2016-09-14 00:40:20,369][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:40:20,369][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:23,380][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:40:23,380][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:40:23,481][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:40:23,882][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:23,883][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:40:23,888][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 360) with member_id kafka-python-1.3.1-21d03dd0-a3c0-488f-a144-8fe57e7af7eb
[2016-09-14 00:40:23,889][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:40:27,399][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 361) with member_id kafka-python-1.3.1-21d03dd0-a3c0-488f-a144-8fe57e7af7eb
[2016-09-14 00:40:27,400][kafka.coordinator.consumer][WARNING]Auto offset commit failed for group kafka-python-default-group: CommitFailedError: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured session.timeout.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
[2016-09-14 00:40:27,401][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 361
[2016-09-14 00:40:27,401][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:40:27,402][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:30,411][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:40:30,411][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:40:30,513][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:40:30,914][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:30,914][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:40:30,916][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 362) with member_id kafka-python-1.3.1-21d03dd0-a3c0-488f-a144-8fe57e7af7eb
[2016-09-14 00:40:30,918][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 362
[2016-09-14 00:40:30,918][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:40:30,918][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:33,928][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:40:33,928][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:40:34,029][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:40:34,429][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:34,430][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:40:34,433][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 363) with member_id kafka-python-1.3.1-21d03dd0-a3c0-488f-a144-8fe57e7af7eb
[2016-09-14 00:40:34,435][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 363
[2016-09-14 00:40:34,435][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:40:34,435][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:37,445][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:40:37,445][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:40:37,546][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:40:37,946][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:37,946][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:40:37,949][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 364) with member_id kafka-python-1.3.1-21d03dd0-a3c0-488f-a144-8fe57e7af7eb
[2016-09-14 00:40:37,951][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 364
[2016-09-14 00:40:37,951][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:40:37,951][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:40,962][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:40:40,962][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:40:41,063][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:40:41,464][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:41,464][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:40:41,466][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 365) with member_id kafka-python-1.3.1-21d03dd0-a3c0-488f-a144-8fe57e7af7eb
[2016-09-14 00:40:41,467][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 365
[2016-09-14 00:40:41,467][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:40:41,468][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:44,479][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:40:44,479][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:40:44,580][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:40:44,980][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:44,980][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:40:44,985][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 366) with member_id kafka-python-1.3.1-21d03dd0-a3c0-488f-a144-8fe57e7af7eb
[2016-09-14 00:40:44,986][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:40:48,498][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 367) with member_id kafka-python-1.3.1-21d03dd0-a3c0-488f-a144-8fe57e7af7eb
[2016-09-14 00:40:48,499][kafka.coordinator.consumer][WARNING]Auto offset commit failed for group kafka-python-default-group: CommitFailedError: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured session.timeout.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
[2016-09-14 00:40:48,502][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 367
[2016-09-14 00:40:48,502][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:40:48,502][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:51,512][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:40:51,513][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:40:51,614][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:40:52,014][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:52,014][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:40:52,017][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 368) with member_id kafka-python-1.3.1-21d03dd0-a3c0-488f-a144-8fe57e7af7eb
[2016-09-14 00:40:52,020][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 368
[2016-09-14 00:40:52,020][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:40:52,021][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:55,030][kafka.coordinator][WARNING]Heartbeat failed for group kafka-python-default-group because it is rebalancing
[2016-09-14 00:40:55,030][kafka.coordinator][WARNING]Heartbeat failed ([Error 27] RebalanceInProgressError: ); retrying
[2016-09-14 00:40:55,131][kafka.coordinator][INFO]Skipping heartbeat: no auto-assignment or waiting on rebalance
[2016-09-14 00:40:55,533][kafka.coordinator.consumer][INFO]Revoking previously assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
[2016-09-14 00:40:55,533][kafka.coordinator][INFO](Re-)joining group kafka-python-default-group
[2016-09-14 00:40:55,535][kafka.coordinator][INFO]Joined group 'kafka-python-default-group' (generation 369) with member_id kafka-python-1.3.1-21d03dd0-a3c0-488f-a144-8fe57e7af7eb
[2016-09-14 00:40:55,537][kafka.coordinator][INFO]Successfully joined group kafka-python-default-group with generation 369
[2016-09-14 00:40:55,538][kafka.consumer.subscription_state][INFO]Updated partition assignment: [TopicPartition(topic=u'spamtopic', partition=0)]
[2016-09-14 00:40:55,538][kafka.coordinator.consumer][INFO]Setting newly assigned partitions set([TopicPartition(topic=u'spamtopic', partition=0)]) for group kafka-python-default-group
